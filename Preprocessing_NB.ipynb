{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bada8c77",
   "metadata": {},
   "source": [
    "# **Avalanche Risk Project**\n",
    "\n",
    "Advanced Data Analytics, Fall 2025\n",
    "\n",
    "The following project examines the feasibility of machine learning models to predict dry avalanche danger from spatial and meteorological features for the Davos Valley. In a second step, the model will be trained on the whole of Switzerland and tested as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bbc72",
   "metadata": {},
   "source": [
    "### **1. Data Import**\n",
    "\n",
    "I start by importing all necessary data from the different APIs including:\n",
    "\n",
    "- SLF Bulletin Archive\n",
    "- Meteo Swiss IMIS Data Archive\n",
    "- SwissTopo Spatial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493da979",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'beautifulsoup4'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbeautifulsoup4\u001b[39;00m \n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'beautifulsoup4'"
     ]
    }
   ],
   "source": [
    "# Necessary Libraries \n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import beautifulsoup4 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f6434d",
   "metadata": {},
   "source": [
    "Apparently, the API only returns data from 2024 onwards. That means I have to scrape the data from the SLF archive using `Beautiful Soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3082246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bulletins: 9\n",
      "\n",
      "==================================================\n",
      "First bulletin keys:\n",
      "{\n",
      "  \"bulletinID\": \"a7480e81-950a-4036-856c-a5497803260d\",\n",
      "  \"validTime\": {\n",
      "    \"startTime\": \"2024-01-15T07:00:00Z\",\n",
      "    \"endTime\": \"2024-01-15T16:00:00Z\"\n",
      "  },\n",
      "  \"nextUpdate\": \"2024-01-15T16:00:00Z\",\n",
      "  \"publicationTime\": \"2024-01-15T06:50:08.489548751Z\",\n",
      "  \"lang\": \"en\",\n",
      "  \"regions\": [\n",
      "    {\n",
      "      \"regionID\": \"CH-4244\",\n",
      "      \"name\": \"s\\u00fcdliches Obergoms\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-2223\",\n",
      "      \"name\": \"n\\u00f6rdliches Urseren\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-1312\",\n",
      "      \"name\": \"Monthey-Val d'Illiez\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4242\",\n",
      "      \"name\": \"Binntal\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4231\",\n",
      "      \"name\": \"n\\u00f6rdliches Simplon Gebiet\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4114\",\n",
      "      \"name\": \"Conthey-Fully\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-1245\",\n",
      "      \"name\": \"Guttannen\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4241\",\n",
      "      \"name\": \"Reckingen\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-1114\",\n",
      "      \"name\": \"Bex-Villars\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4213\",\n",
      "      \"name\": \"Konkordia Gebiet\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4214\",\n",
      "      \"name\": \"Riederalp\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-5124\",\n",
      "      \"name\": \"Flims\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-1247\",\n",
      "      \"name\": \"Grimselpass\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-1243\",\n",
      "      \"name\": \"Schreckhorn\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4121\",\n",
      "      \"name\": \"Montana\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4215\",\n",
      "      \"name\": \"Leuk\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-5211\",\n",
      "      \"name\": \"n\\u00f6rdliches Tujetsch\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4243\",\n",
      "      \"name\": \"n\\u00f6rdliches Obergoms\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-4211\",\n",
      "      \"name\": \"Leukerbad - L\\u00f6tschental\"\n",
      "    },\n",
      "    {\n",
      "      \"regionID\": \"CH-2224\",\n",
      "      \"name\": \"s\\u00fcdliches Urseren\"\n",
      "    }\n",
      "  ],\n",
      "  \"dangerRatings\": [\n",
      "    {\n",
      "      \"mainValue\": \"considerable\",\n",
      "      \"validTimePeriod\": \"all_day\",\n",
      "      \"customData\": {\n",
      "        \"CH\": {\n",
      "          \"subdivision\": \"minus\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"avalancheProblems\": [\n",
      "  \n",
      "\n",
      "==================================================\n",
      "Extracting danger ratings...\n",
      "\n",
      "\n",
      "Bulletin 1:\n",
      "  Danger Level: considerable\n",
      "  Elevation: {}\n",
      "  Regions: südliches Obergoms, nördliches Urseren, Monthey-Val d'Illiez...\n",
      "\n",
      "Bulletin 2:\n",
      "  Danger Level: considerable\n",
      "  Elevation: {}\n",
      "  Regions: Zermatt, Saas Fee, Val d'Hérens...\n",
      "\n",
      "Bulletin 3:\n",
      "  Danger Level: considerable\n",
      "  Elevation: {}\n",
      "  Regions: Gadmertal, Iffigen, Gstaad...\n",
      "\n",
      "Bulletin 4:\n",
      "  Danger Level: moderate\n",
      "  Elevation: {}\n",
      "  Regions: östliche Berner Voralpen, Toggenburg, Appenzeller Alpen...\n",
      "\n",
      "Bulletin 5:\n",
      "  Danger Level: moderate\n",
      "  Elevation: {}\n",
      "  Regions: Münstertal, unteres Puschlav, Corvatsch...\n",
      "\n",
      "Bulletin 6:\n",
      "  Danger Level: moderate\n",
      "  Elevation: {}\n",
      "  Regions: Vouvry, Hohgant, Glarus Nord...\n",
      "\n",
      "Bulletin 7:\n",
      "  Danger Level: moderate\n",
      "  Elevation: {}\n",
      "  Regions: basso Moesano, obere Leventina, untere Leventina...\n",
      "\n",
      "Bulletin 8:\n",
      "  Danger Level: low\n",
      "  Elevation: {}\n",
      "  Regions: Yverdon - Bevaix, Val de Travers, Moutier - Tavannes...\n",
      "\n",
      "Bulletin 9:\n",
      "  Danger Level: low\n",
      "  Elevation: {}\n",
      "  Regions: Luganese, Riviera, Mendrisiotto...\n"
     ]
    }
   ],
   "source": [
    "# Get the Bulletin Data from SLF API\n",
    "def fetch_bulletin_json(date):\n",
    "    url = \"https://aws.slf.ch/api/bulletin/caaml/en/json\"\n",
    "    params = {'activeAt': date.strftime('%Y-%m-%dT08:00:00+01:00')}\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Fetch a winter day with actual danger\n",
    "historical = fetch_bulletin_json(datetime(2024, 1, 15))\n",
    "\n",
    "print(f\"Number of bulletins: {len(historical['bulletins'])}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Look at first bulletin structure\n",
    "first_bulletin = historical['bulletins'][0]\n",
    "print(\"First bulletin keys:\")\n",
    "print(json.dumps(first_bulletin, indent=2)[:2000])\n",
    "\n",
    "# Try to find danger ratings\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Extracting danger ratings...\\n\")\n",
    "\n",
    "for i, bulletin in enumerate(historical['bulletins']):\n",
    "    print(f\"\\nBulletin {i+1}:\")\n",
    "    \n",
    "    # Look for danger ratings\n",
    "    if 'dangerRatings' in bulletin:\n",
    "        for rating in bulletin['dangerRatings']:\n",
    "            danger_level = rating.get('mainValue', 'N/A')\n",
    "            regions = rating.get('validElevation', {})\n",
    "            \n",
    "            print(f\"  Danger Level: {danger_level}\")\n",
    "            print(f\"  Elevation: {regions}\")\n",
    "    \n",
    "    # Get regions\n",
    "    if 'regions' in bulletin:\n",
    "        region_names = [r.get('name', 'Unknown') for r in bulletin['regions'][:3]]\n",
    "        print(f\"  Regions: {', '.join(region_names)}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b047d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching bulletins from 2014 to 2024 for Davos region...\n",
      "Date range: 2014-11-01 to 2024-05-31\n",
      "\n",
      "Progress: 2023-11-14 - Records collected: 14\n",
      "Progress: 2023-11-14 - Records collected: 14\n",
      "Progress: 2024-02-22 - Records collected: 114\n",
      "Progress: 2024-02-22 - Records collected: 114\n",
      "\n",
      "============================================================\n",
      "Data collection complete!\n",
      "Total records: 209\n",
      "Failed dates: 3294\n",
      "DataFrame shape: (209, 7)\n",
      "Date range in data: 2023-11-01 to 2024-05-31\n",
      "Unique region names found: 142\n",
      "First few region names: ['Génépi', 'nördliches Tujetsch', 'Jungfrau - Schilthorn', 'Bernina', 'Stoos', 'Toggenburg', 'Blüemlisalp', 'Saint-Cergue', 'Maderanertal', 'Val dal Spöl']\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "Data collection complete!\n",
      "Total records: 209\n",
      "Failed dates: 3294\n",
      "DataFrame shape: (209, 7)\n",
      "Date range in data: 2023-11-01 to 2024-05-31\n",
      "Unique region names found: 142\n",
      "First few region names: ['Génépi', 'nördliches Tujetsch', 'Jungfrau - Schilthorn', 'Bernina', 'Stoos', 'Toggenburg', 'Blüemlisalp', 'Saint-Cergue', 'Maderanertal', 'Val dal Spöl']\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>regions</th>\n",
       "      <th>region_ids</th>\n",
       "      <th>danger_level</th>\n",
       "      <th>elevation_lower</th>\n",
       "      <th>elevation_upper</th>\n",
       "      <th>aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>Bex-Villars, Wildhorn, Iffigen, Engstligen, Bl...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>Gadmertal, Engelberg, Schächental, Uri Rot Sto...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , ,</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-03</td>\n",
       "      <td>Gadmertal, Engelberg, Schächental, Uri Rot Sto...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-04</td>\n",
       "      <td>Engstligen, Blüemlisalp, Jungfrau - Schilthorn...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>Waadtländer Voralpen, Jaun, Hohgant, Niedersim...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>Waadtländer Voralpen, Jaun, Hohgant, Niedersim...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>Pays d'Enhaut, Aigle-Leysin, Gstaad, Lenk, Ade...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>Pays d'Enhaut, Aigle-Leysin, Gstaad, Lenk, Ade...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>Pays d'Enhaut, Aigle-Leysin, Gstaad, Lenk, Eng...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>Ybrig, Stoos, Bisistal, Glarus Nord, Glarus Sü...</td>\n",
       "      <td>, , , , , , , , , , , , , , , , , , , , , , , ...</td>\n",
       "      <td>moderate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                            regions  \\\n",
       "0  2023-11-01  Bex-Villars, Wildhorn, Iffigen, Engstligen, Bl...   \n",
       "1  2023-11-02  Gadmertal, Engelberg, Schächental, Uri Rot Sto...   \n",
       "2  2023-11-03  Gadmertal, Engelberg, Schächental, Uri Rot Sto...   \n",
       "3  2023-11-04  Engstligen, Blüemlisalp, Jungfrau - Schilthorn...   \n",
       "4  2023-11-05  Waadtländer Voralpen, Jaun, Hohgant, Niedersim...   \n",
       "5  2023-11-06  Waadtländer Voralpen, Jaun, Hohgant, Niedersim...   \n",
       "6  2023-11-07  Pays d'Enhaut, Aigle-Leysin, Gstaad, Lenk, Ade...   \n",
       "7  2023-11-08  Pays d'Enhaut, Aigle-Leysin, Gstaad, Lenk, Ade...   \n",
       "8  2023-11-09  Pays d'Enhaut, Aigle-Leysin, Gstaad, Lenk, Eng...   \n",
       "9  2023-11-10  Ybrig, Stoos, Bisistal, Glarus Nord, Glarus Sü...   \n",
       "\n",
       "                                          region_ids danger_level  \\\n",
       "0  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "1       , , , , , , , , , , , , , , , , , , , , , ,      moderate   \n",
       "2  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "3  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "4  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "5  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "6  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "7  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "8  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "9  , , , , , , , , , , , , , , , , , , , , , , , ...     moderate   \n",
       "\n",
       "  elevation_lower elevation_upper aspects  \n",
       "0            None            None          \n",
       "1            None            None          \n",
       "2            None            None          \n",
       "3            None            None          \n",
       "4            None            None          \n",
       "5            None            None          \n",
       "6            None            None          \n",
       "7            None            None          \n",
       "8            None            None          \n",
       "9            None            None          "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch all bulletins from 2014-2024 for Davos region\n",
    "start_date = datetime(2014, 11, 1)  # Winter season starts in November\n",
    "end_date = datetime(2024, 5, 31)    # Winter season ends in May\n",
    "current_date = start_date\n",
    "\n",
    "# Extract data into list of records\n",
    "records = []\n",
    "failed_dates = []\n",
    "all_region_names = set()  # To track unique region names\n",
    "\n",
    "print(\"Fetching bulletins from 2014 to 2024 for Davos region...\")\n",
    "print(f\"Date range: {start_date.date()} to {end_date.date()}\\n\")\n",
    "\n",
    "# Iterate through all dates\n",
    "while current_date <= end_date:\n",
    "    try:\n",
    "        bulletin_json = fetch_bulletin_json(current_date)\n",
    "        \n",
    "        # Check if bulletins exist\n",
    "        if not bulletin_json.get('bulletins'):\n",
    "            failed_dates.append(current_date.date())\n",
    "            current_date += timedelta(days=1)\n",
    "            continue\n",
    "        \n",
    "        for bulletin in bulletin_json.get('bulletins', []):\n",
    "            regions = bulletin.get('regions', [])\n",
    "            \n",
    "            # Collect region names and IDs\n",
    "            region_names = []\n",
    "            region_ids = []\n",
    "            for r in regions:\n",
    "                name = r.get('name', '')\n",
    "                region_id = r.get('regionId', '')\n",
    "                region_names.append(name)\n",
    "                region_ids.append(region_id)\n",
    "                all_region_names.add(name)\n",
    "            \n",
    "            # Filter for Davos region - check both name and ID\n",
    "            # Davos region ID is typically \"CH-7114\" or similar\n",
    "            is_davos = any(\n",
    "                'davos' in name.lower() or \n",
    "                'davos' in rid.lower() or\n",
    "                'CH-7114' in rid or\n",
    "                'CH-7115' in rid\n",
    "                for name, rid in zip(region_names, region_ids)\n",
    "            )\n",
    "            \n",
    "            if is_davos:\n",
    "                danger_ratings = bulletin.get('dangerRatings', [])\n",
    "                for rating in danger_ratings:\n",
    "                    records.append({\n",
    "                        'date': current_date.date(),\n",
    "                        'regions': ', '.join(region_names),\n",
    "                        'region_ids': ', '.join(region_ids),\n",
    "                        'danger_level': rating.get('mainValue', 'N/A'),\n",
    "                        'elevation_lower': rating.get('validElevation', {}).get('lowerBound'),\n",
    "                        'elevation_upper': rating.get('validElevation', {}).get('upperBound'),\n",
    "                        'aspects': ', '.join(rating.get('aspects', []))\n",
    "                    })\n",
    "        \n",
    "        # Print progress every 100 days\n",
    "        if (current_date - start_date).days % 100 == 0:\n",
    "            print(f\"Progress: {current_date.date()} - Records collected: {len(records)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        failed_dates.append(current_date.date())\n",
    "    \n",
    "    # Move to next day\n",
    "    current_date += timedelta(days=1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_bulletins = pd.DataFrame(records)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Data collection complete!\")\n",
    "print(f\"Total records: {len(records)}\")\n",
    "print(f\"Failed dates: {len(failed_dates)}\")\n",
    "print(f\"DataFrame shape: {df_bulletins.shape}\")\n",
    "if len(df_bulletins) > 0:\n",
    "    print(f\"Date range in data: {df_bulletins['date'].min()} to {df_bulletins['date'].max()}\")\n",
    "print(f\"Unique region names found: {len(all_region_names)}\")\n",
    "print(f\"First few region names: {list(all_region_names)[:10]}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "df_bulletins.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11245f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data availability across years:\n",
      "\n",
      "============================================================\n",
      "2014-01: ✗ No data\n",
      "\n",
      "2014-01: ✗ No data\n",
      "\n",
      "2016-01: ✗ No data\n",
      "\n",
      "2016-01: ✗ No data\n",
      "\n",
      "2018-01: ✗ No data\n",
      "\n",
      "2018-01: ✗ No data\n",
      "\n",
      "2020-01: ✗ No data\n",
      "\n",
      "2020-01: ✗ No data\n",
      "\n",
      "2022-01: ✗ No data\n",
      "\n",
      "2022-01: ✗ No data\n",
      "\n",
      "2024-01: ✓ 9 bulletins, 140 regions\n",
      "  Davos found: YES\n",
      "  Davos regions: {'Davos'}\n",
      "\n",
      "2024-01: ✓ 9 bulletins, 140 regions\n",
      "  Davos found: YES\n",
      "  Davos regions: {'Davos'}\n",
      "\n",
      "============================================================\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "def fetch_bulletin_json(date, lang='en'):\n",
    "    \"\"\"Fetch bulletin as JSON\"\"\"\n",
    "    url = f\"https://aws.slf.ch/api/bulletin/caaml/{lang}/json\"\n",
    "    params = {'activeAt': date.strftime('%Y-%m-%dT08:00:00+01:00')}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Test different years to see what's available\n",
    "test_dates = [\n",
    "    datetime(2014, 1, 15),\n",
    "    datetime(2016, 1, 15),\n",
    "    datetime(2018, 1, 15),\n",
    "    datetime(2020, 1, 15),\n",
    "    datetime(2022, 1, 15),\n",
    "    datetime(2024, 1, 15),\n",
    "]\n",
    "\n",
    "print(\"Testing data availability across years:\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for date in test_dates:\n",
    "    data = fetch_bulletin_json(date)\n",
    "    \n",
    "    if data and data.get('bulletins'):\n",
    "        num_bulletins = len(data['bulletins'])\n",
    "        \n",
    "        # Get all region names\n",
    "        all_regions = []\n",
    "        for bulletin in data['bulletins']:\n",
    "            for region in bulletin.get('regions', []):\n",
    "                all_regions.append(region.get('name'))\n",
    "        \n",
    "        # Check for Davos\n",
    "        davos_found = any('davos' in r.lower() for r in all_regions if r)\n",
    "        \n",
    "        print(f\"{date.year}-{date.month:02d}: ✓ {num_bulletins} bulletins, {len(set(all_regions))} regions\")\n",
    "        print(f\"  Davos found: {'YES' if davos_found else 'NO'}\")\n",
    "        if davos_found:\n",
    "            davos_regions = [r for r in all_regions if 'davos' in r.lower()]\n",
    "            print(f\"  Davos regions: {set(davos_regions)}\")\n",
    "    else:\n",
    "        print(f\"{date.year}-{date.month:02d}: ✗ No data\")\n",
    "    \n",
    "    print()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b279bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- CONFIGURATION ---------------------------------------------------\n",
    "REGION_NAME = \"Davos\"                   # region you work on\n",
    "START_DATE = \"2022-11-01\"               # example start\n",
    "END_DATE   = \"2023-04-30\"               # example end\n",
    "STATION_IDS = [\"WFJ2\", \"DAV2\"]          # example station codes for Davos region\n",
    "\n",
    "# STAC base URL for MeteoSwiss via FSDI\n",
    "STAC_BASE = \"https://data.geo.admin.ch/api/stac/v1\"\n",
    "\n",
    "# Collection names for station data (example)\n",
    "COL_AUTO_WS  = \"ch.meteoschweiz.ogd-smn\"      # automatic weather stations (temp, wind, etc) :contentReference[oaicite:3]{index=3}\n",
    "COL_PRECIP   = \"ch.meteoschweiz.ogd-smn-precip\"  # automatic precipitation stations :contentReference[oaicite:4]{index=4}\n",
    "\n",
    "# Bulletin endpoint placeholder (you’ll need to confirm actual URL)\n",
    "BULLETIN_URL = \"https://www.slf.ch/fileadmin/content/lawinenbulletin/daten/json/bulletin.json\"\n",
    "\n",
    "# --- FUNCTIONS ------------------------------------------------------\n",
    "\n",
    "def fetch_station_data(collection, station_id, start_date, end_date):\n",
    "    \"\"\"Fetch station data for a specific station from STAC API.\"\"\"\n",
    "    params = {\n",
    "        \"time\": f\"{start_date}T00:00:00Z/{end_date}T23:59:59Z\",\n",
    "        \"properties\": f\"station:{station_id}\"\n",
    "    }\n",
    "    url = f\"{STAC_BASE}/collections/{collection}/items\"\n",
    "    resp = requests.get(url, params=params)\n",
    "    resp.raise_for_status()\n",
    "    features = resp.json().get(\"features\", [])\n",
    "    # convert to DataFrame: flatten each feature’s assets etc\n",
    "    records = []\n",
    "    for feat in features:\n",
    "        rec = {\n",
    "            \"time\": feat[\"properties\"][\"datetime\"],\n",
    "            \"station_id\": station_id\n",
    "        }\n",
    "        # You may want to parse assets or properties depending on dataset\n",
    "        # rec[\"temp\"] = feat[\"properties\"].get(\"t2m\")\n",
    "        records.append(rec)\n",
    "    df = pd.DataFrame.from_records(records)\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    return df\n",
    "\n",
    "def fetch_bulletin_data():\n",
    "    \"\"\"Fetch the bulletin JSON and extract region danger levels.\"\"\"\n",
    "    resp = requests.get(BULLETIN_URL)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    # You’ll need to inspect structure → Example:\n",
    "    # regions_data = data[\"regions\"]\n",
    "    # Filter for REGION_NAME\n",
    "    rows = []\n",
    "    for r in data.get(\"regions\", []):\n",
    "        if r.get(\"region_name\") == REGION_NAME:\n",
    "            rows.append({\n",
    "                \"date\": pd.to_datetime(r[\"date\"]),\n",
    "                \"danger_level\": r[\"danger_level\"]\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- MAIN SCRIPT ----------------------------------------------------\n",
    "\n",
    "# 1. Fetch danger level (target)\n",
    "df_danger = fetch_bulletin_data()\n",
    "print(\"Danger levels:\", df_danger.head())\n",
    "\n",
    "# 2. Fetch station feature data (loop over collections & stations)\n",
    "df_list = []\n",
    "for station in STATION_IDS:\n",
    "    df_temp = fetch_station_data(COL_AUTO_WS, station, START_DATE, END_DATE)\n",
    "    df_prec = fetch_station_data(COL_PRECIP, station, START_DATE, END_DATE)\n",
    "    # merge or pivot as needed\n",
    "    df_station = df_temp.merge(df_prec, on=[\"time\",\"station_id\"], how=\"outer\")\n",
    "    df_list.append(df_station)\n",
    "\n",
    "df_features = pd.concat(df_list, axis=0).reset_index(drop=True)\n",
    "print(\"Features data:\", df_features.head())\n",
    "\n",
    "# 3. Merge features + danger by date\n",
    "df_features[\"date\"] = df_features[\"time\"].dt.date\n",
    "df_danger[\"date\"] = df_danger[\"date\"].dt.date\n",
    "df_merged = pd.merge(df_features, df_danger, on=\"date\", how=\"left\")\n",
    "\n",
    "print(\"Merged dataset sample:\\n\", df_merged.head())\n",
    "\n",
    "# 4. Save to CSV\n",
    "df_merged.to_csv(\"data/davos_features_danger.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avalanche_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
