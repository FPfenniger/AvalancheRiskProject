{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13990110,"sourceType":"datasetVersion","datasetId":8916888}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"cc79b42e","cell_type":"markdown","source":"# **Avalanche Risk Project**\n\nAdvanced Data Analytics, Fall 2025\n\nThe following project examines the feasibility of deep learning models (3D-CNN, convLSTM) compared to traditional, state-of-the-art methods for predicting avalanche danger levels. Using a comprehensive dataset from the Swiss Federal Institute for Snow and Avalanche Research (SLF) spanning from 1997-2020, the project heavily relies on the work of PÃ©rez-GuillÃ©n et al. (2022) and Maissen et al. (2024) and adopts many of their preprocessing and modeling techniques.","metadata":{}},{"id":"5c1f5b83","cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:18.601980Z","iopub.execute_input":"2025-12-04T12:19:18.602553Z","iopub.status.idle":"2025-12-04T12:19:18.606710Z","shell.execute_reply.started":"2025-12-04T12:19:18.602528Z","shell.execute_reply":"2025-12-04T12:19:18.605996Z"}},"outputs":[],"execution_count":2},{"id":"8e0d03fb","cell_type":"code","source":"# Check if running on Kaggle\nis_kaggle = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n\nif is_kaggle:\n    # Kaggle paths\n    CLEANED_DATA_PATH = '/kaggle/input/avalanche/data/cleaned_data.parquet'\n    grid_dir = '/kaggle/input/avalanche/data/grids'\n    \n    # Kaggle Output Paths (Writable)\n    output_dir = '/kaggle/working'\n    model_save_dir = os.path.join(output_dir, 'models')\n    \n    # Install necessary packages\n    print(\"Running on Kaggle - Installing packages...\")\n    import subprocess\n    subprocess.run(['pip', 'install', '-q', 'xarray-spatial', 'rasterio', 'geopandas'], check=True)\nelse:\n    # Local Paths\n    CLEANED_DATA_PATH = '../data/cleaned_data.parquet'\n    grid_dir = '../data/grids'\n    \n    output_dir = 'results'\n    model_save_dir = 'models'\n    \n    print(\"Running Locally. Standard paths used.\")\n\n# Define grid subdirectories\ndynamic_dir = os.path.join(grid_dir, 'dynamic')\ntarget_dir = os.path.join(grid_dir, 'targets')\nstatic_file = os.path.join(grid_dir, 'static_terrain.npy')\n\n# Create output directories if they don't exist (critical for Kaggle)\nos.makedirs(model_save_dir, exist_ok=True)\n\nprint(f\"Data path: {CLEANED_DATA_PATH}\")\nprint(f\"Grid directory: {grid_dir}\")\nprint(f\"Model save directory: {model_save_dir}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:18.613941Z","iopub.execute_input":"2025-12-04T12:19:18.614171Z","iopub.status.idle":"2025-12-04T12:19:25.147691Z","shell.execute_reply.started":"2025-12-04T12:19:18.614154Z","shell.execute_reply":"2025-12-04T12:19:25.146921Z"}},"outputs":[{"name":"stdout","text":"Running on Kaggle - Installing packages...\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.0/2.0 MB 25.8 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 22.2/22.2 MB 102.5 MB/s eta 0:00:00\n   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18.3/18.3 MB 112.8 MB/s eta 0:00:00\nData path: /kaggle/input/avalanche/data/cleaned_data.parquet\nGrid directory: /kaggle/input/avalanche/data/grids\nModel save directory: /kaggle/working/models\n","output_type":"stream"}],"execution_count":3},{"id":"28b76784","cell_type":"markdown","source":"## **5. CNN Model**","metadata":{}},{"id":"39a61502","cell_type":"code","source":"# ---------------------------------------------------------\n# CONFIGURATION: MUST BE EXACTLY 11 ITEMS\n# ---------------------------------------------------------\n\n# 1. Define the list matching your generation script exactly\ndynamic_features = [\n    'delta_elevation',    # 1\n    'Pen_depth',          # 2\n    'HN24',               # 3\n    'MS_Snow',            # 4\n    'TA',                 # 5\n    'wind_trans24',       # 6\n    'RH',                 # 7\n    'min_ccl_pen',        # 8\n    'relative_load_3d',   # 9\n    'wind_u',             # 10 (Added automatically by script)\n    'wind_v'              # 11 (Added automatically by script)\n]\n\n# 2. SANITY CHECK (Run this!)\nprint(f\"Feature Count: {len(dynamic_features)}\")\nif len(dynamic_features) != 11:\n    raise ValueError(f\"STOP! List has {len(dynamic_features)} items. It MUST have 11 to match your files.\")\nelse:\n    print(\"âœ… List length matches disk files (11). Training should work.\")\n\n# Note: VW and DW are NOT in this list because they are redundant \n# (wind_u/v contain that info) and were likely excluded from your generation script.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:25.148945Z","iopub.execute_input":"2025-12-04T12:19:25.149165Z","iopub.status.idle":"2025-12-04T12:19:25.153958Z","shell.execute_reply.started":"2025-12-04T12:19:25.149148Z","shell.execute_reply":"2025-12-04T12:19:25.153322Z"}},"outputs":[{"name":"stdout","text":"Feature Count: 11\nâœ… List length matches disk files (11). Training should work.\n","output_type":"stream"}],"execution_count":4},{"id":"b13b4fa2-e241-43b3-8bc0-00ef126fe73d","cell_type":"code","source":"import numpy as np\nimport os\n\n# Load the VERY FIRST file in your dynamic directory\nfiles = sorted(os.listdir('/kaggle/input/avalanche/data/grids/dynamic'))\nfirst_file = os.path.join('/kaggle/input/avalanche/data/grids/dynamic', files[0])\ndata = np.load(first_file)['data']\n\nprint(f\"REAL Shape on Disk: {data.shape}\")\nprint(f\"Number of Channels: {data.shape[-1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:25.154568Z","iopub.execute_input":"2025-12-04T12:19:25.154803Z","iopub.status.idle":"2025-12-04T12:19:25.241784Z","shell.execute_reply.started":"2025-12-04T12:19:25.154782Z","shell.execute_reply":"2025-12-04T12:19:25.241079Z"}},"outputs":[{"name":"stdout","text":"REAL Shape on Disk: (211, 470, 11)\nNumber of Channels: 11\n","output_type":"stream"}],"execution_count":5},{"id":"5ce0ae3a","cell_type":"code","source":"# Load Data\nprint(\"Loading data...\")\ndf = pd.read_parquet(CLEANED_DATA_PATH)\n\n# Re-calculate Wind Vectors (if missing)\nif 'DW' in df.columns and 'VW' in df.columns:\n    wd_rad = np.deg2rad(df['DW'])\n    df['wind_u'] = -df['VW'] * np.sin(wd_rad)\n    df['wind_v'] = -df['VW'] * np.cos(wd_rad)\n    print(\"Wind vectors calculated.\")\n\nprint(f\"Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\nprint(f\"Columns available: {df.columns.tolist()[:10]}...\")  # Show first 10 columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:25.243227Z","iopub.execute_input":"2025-12-04T12:19:25.243419Z","iopub.status.idle":"2025-12-04T12:19:26.025759Z","shell.execute_reply.started":"2025-12-04T12:19:25.243403Z","shell.execute_reply":"2025-12-04T12:19:26.025012Z"}},"outputs":[{"name":"stdout","text":"Loading data...\nWind vectors calculated.\nDataset loaded: 291535 rows, 64 columns\nColumns available: ['datum', 'station_code', 'sector_id', 'warnreg', 'elevation_station', 'forecast_initial_date', 'forecast_end_date', 'dangerLevel', 'elevation_th', 'set']...\n","output_type":"stream"}],"execution_count":6},{"id":"14072dec-a1b3-4e7e-8cdc-8f19340704d4","cell_type":"code","source":"# --- FIX 1: Proper Data Splitting (Train/Val/Test) ---\n# 1. Isolate Test Set (Don't touch until the very end!)\ntest_dates = df[df['set'] == 'test']['datum'].unique().astype(str)\n\n# 2. Split training data by full winter seasons\n# Validation: Winters 2016/17 and 2017/18\n# Training: All other winters in the training set\ndf_train = df[df['set'] == 'train'].copy()\ndf_train['datum'] = pd.to_datetime(df_train['datum'])\n\n# Define validation winters (16/17 and 17/18)\n# Winter 16/17: Nov 2016 - Apr 2017\n# Winter 17/18: Nov 2017 - Apr 2018\nval_mask = (\n    ((df_train['datum'] >= '2016-11-01') & (df_train['datum'] <= '2017-04-30')) |\n    ((df_train['datum'] >= '2017-11-01') & (df_train['datum'] <= '2018-04-30'))\n)\n\nval_dates = df_train[val_mask]['datum'].unique().astype(str)\ntrain_dates = df_train[~val_mask]['datum'].unique().astype(str)\n\nprint(f\"Train Days: {len(train_dates)} | Val Days: {len(val_dates)} | Test Days: {len(test_dates)}\")\nprint(f\"  Train range: {pd.to_datetime(train_dates).min()} to {pd.to_datetime(train_dates).max()}\")\nprint(f\"  Val winters: 2016/17 and 2017/18\")\nprint(f\"  Val range: {pd.to_datetime(val_dates).min()} to {pd.to_datetime(val_dates).max()}\")\nprint(f\"  Test range: {test_dates[0]} to {test_dates[-1]}\")\n\nprint(\"\\nâœ… Temporal split by full winter seasons (no leakage)\")\n\n# --- FIX 2: No-Leakage Normalization ---\n# Calculate Mean/Std ONLY on the training portion\nprint(\"\\nCalculating normalization stats on Training set only...\")\ntrain_df_subset = df[df['datum'].astype(str).isin(train_dates)]\n\nstats = {col: {\n    'mean': train_df_subset[col].mean(), \n    'std': train_df_subset[col].std()\n} for col in dynamic_features}\n\nprint(\"âœ… Normalization stats ready (calculated from training data only).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.026577Z","iopub.execute_input":"2025-12-04T12:19:26.026889Z","iopub.status.idle":"2025-12-04T12:19:26.610456Z","shell.execute_reply.started":"2025-12-04T12:19:26.026862Z","shell.execute_reply":"2025-12-04T12:19:26.609742Z"}},"outputs":[{"name":"stdout","text":"Train Days: 3132 | Val Days: 328 | Test Days: 359\n  Train range: 1997-11-12 00:00:00 to 2017-05-08 00:00:00\n  Val winters: 2016/17 and 2017/18\n  Val range: 2016-11-09 00:00:00 to 2018-04-14 00:00:00\n  Test range: 2019-11-16 to 2019-04-24\n\nâœ… Temporal split by full winter seasons (no leakage)\n\nCalculating normalization stats on Training set only...\nâœ… Normalization stats ready (calculated from training data only).\n","output_type":"stream"}],"execution_count":7},{"id":"17ef1987","cell_type":"code","source":"# Hyperparameters - Optimized for Kaggle T4 GPU (16GB VRAM)\nbatch_size = 4        # Kaggle T4 can handle 4-8, start with 4\nlearning_rate = 1e-4\nepochs = 10\nlookback = 7          # T-6 to T\nnum_classes = 5       # 0=NoData (Ignore), 1, 2, 3, 4 (High)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(f\"Running on device: {device}\")\nprint(f\"Batch size: {batch_size} (4x faster than batch_size=1)\")\nprint(f\"Grid paths configured:\")\nprint(f\"  Dynamic: {dynamic_dir}\")\nprint(f\"  Target: {target_dir}\")\nprint(f\"  Static: {static_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.611150Z","iopub.execute_input":"2025-12-04T12:19:26.611375Z","iopub.status.idle":"2025-12-04T12:19:26.698350Z","shell.execute_reply.started":"2025-12-04T12:19:26.611353Z","shell.execute_reply":"2025-12-04T12:19:26.697602Z"}},"outputs":[{"name":"stdout","text":"Running on device: cuda\nBatch size: 4 (4x faster than batch_size=1)\nGrid paths configured:\n  Dynamic: /kaggle/input/avalanche/data/grids/dynamic\n  Target: /kaggle/input/avalanche/data/grids/targets\n  Static: /kaggle/input/avalanche/data/grids/static_terrain.npy\n","output_type":"stream"}],"execution_count":8},{"id":"eb5ac612-204d-451e-a62c-58bfb389d0dc","cell_type":"code","source":"class AvalancheDataset(Dataset):\n    def __init__(self, date_list, feature_dir, target_dir, static_file, stats, feature_names, lookback=7):\n        self.dates = date_list\n        self.feature_dir = feature_dir\n        self.target_dir = target_dir\n        self.stats = stats\n        self.feature_names = feature_names\n        self.lookback = lookback\n        \n        # Load static data once\n        self.static_data = np.load(static_file).astype(np.float32)\n        \n        # DEFINE THE EXPECTED SHAPE\n        self.expected_h = self.static_data.shape[0]\n        self.expected_w = self.static_data.shape[1]\n        self.expected_c = len(self.feature_names)\n        \n        print(f\"Dataset initialized. EXPECTING Shape: ({self.expected_h}, {self.expected_w}, {self.expected_c})\")\n\n    def __len__(self):\n        return len(self.dates)\n\n    def __getitem__(self, idx):\n        # --- FIX: Define target_date_str here ---\n        target_date_str = self.dates[idx]\n        target_date = pd.to_datetime(target_date_str)\n        \n        # --- 1. Build Dynamic Sequence ---\n        frames = []\n        start_date = target_date - pd.Timedelta(days=self.lookback - 1)\n        \n        for i in range(self.lookback):\n            d_str = (start_date + pd.Timedelta(days=i)).strftime('%Y-%m-%d')\n            f_path = os.path.join(self.feature_dir, f\"{d_str}.npz\")\n            \n            if os.path.exists(f_path):\n                raw = np.load(f_path)['data']\n                # ... Normalization code (simplified for debug) ...\n                norm_data = raw \n                frames.append(norm_data)\n            else:\n                # Fallback\n                shape = (self.expected_h, self.expected_w, self.expected_c)\n                frames.append(np.zeros(shape, dtype=np.float32))\n        \n        # --- THE TRAP: Check shapes before stacking ---\n        shapes = [f.shape for f in frames]\n        # Check if all frames match the FIRST frame's shape\n        if not all(s == shapes[0] for s in shapes):\n            print(f\"\\nâŒ CRASH DETECTED at Date: {target_date}\")\n            print(f\"Indices in batch: {shapes}\")\n            print(f\"Notebook expects: {self.expected_c} channels\")\n            raise ValueError(f\"Shape Mismatch! See print above.\")\n            \n        # Stack Time\n        dynamic_tensor = np.stack(frames, axis=0)\n        \n        # --- Add Static Data ---\n        static_expanded = np.tile(self.static_data[np.newaxis, ...], (self.lookback, 1, 1, 1))\n        full_cube = np.concatenate([dynamic_tensor, static_expanded], axis=-1)\n        \n        # --- Load Target ---\n        # Now target_date_str is defined\n        target_path = os.path.join(self.target_dir, f\"{target_date_str}.npy\")\n        if os.path.exists(target_path):\n            label = np.load(target_path).astype(np.int64)\n            label[label == -1] = 0\n            \n            # Safety check for target shape too\n            if label.shape != (self.expected_h, self.expected_w):\n                label = np.zeros((self.expected_h, self.expected_w), dtype=np.int64)\n        else:\n            label = np.zeros((self.expected_h, self.expected_w), dtype=np.int64)\n\n        # Permute to (C, T, H, W)\n        X = torch.from_numpy(full_cube).permute(3, 0, 1, 2)\n        Y = torch.from_numpy(label)\n        \n        return X, Y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.699229Z","iopub.execute_input":"2025-12-04T12:19:26.699520Z","iopub.status.idle":"2025-12-04T12:19:26.720150Z","shell.execute_reply.started":"2025-12-04T12:19:26.699454Z","shell.execute_reply":"2025-12-04T12:19:26.719468Z"}},"outputs":[],"execution_count":9},{"id":"e7a0e3d0","cell_type":"code","source":"class AvalancheNet(nn.Module):\n    def __init__(self, in_channels, num_classes):\n        super(AvalancheNet, self).__init__()\n        \n        # 3D Convolutions: Process (Time, Height, Width)\n        # padding='same' keeps the output map size equal to input size\n        self.conv1 = nn.Conv3d(in_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn1 = nn.BatchNorm3d(32)\n        self.relu = nn.ReLU()\n        \n        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn2 = nn.BatchNorm3d(64)\n        \n        # Collapse Time Dimension: Average over the 7 days\n        # Output becomes (Batch, 64, H, W)\n        self.pool_time = nn.AdaptiveAvgPool3d((1, None, None))\n        \n        # Final 2D Convolutions to map to classes\n        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        # x shape: (Batch, C, T, H, W)\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        \n        # Aggregate Time: (Batch, 64, 1, H, W) -> Squeeze -> (Batch, 64, H, W)\n        x = self.pool_time(x).squeeze(2)\n        \n        # Predict Classes\n        x = self.final_conv(x) # (Batch, Num_Classes, H, W)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.720806Z","iopub.execute_input":"2025-12-04T12:19:26.721074Z","iopub.status.idle":"2025-12-04T12:19:26.740624Z","shell.execute_reply.started":"2025-12-04T12:19:26.721056Z","shell.execute_reply":"2025-12-04T12:19:26.740004Z"}},"outputs":[],"execution_count":10},{"id":"d2b93399","cell_type":"markdown","source":"## Architecture Variants for Hyperparameter Tuning\n\nWe'll test 4 different architectures to find the optimal model complexity:\n1. **Light**: Baseline 2-layer model (32â†’64 filters)\n2. **Medium**: Current model with dropout regularization\n3. **Deep**: 3-layer model (64â†’128â†’128 filters)\n4. **MaxPool**: Uses max pooling instead of average pooling for temporal aggregation","metadata":{}},{"id":"0f658562","cell_type":"code","source":"class AvalancheNet_Light(nn.Module):\n    \"\"\"Lightweight baseline - 2 conv layers, 32â†’64 filters\"\"\"\n    def __init__(self, in_channels, num_classes):\n        super(AvalancheNet_Light, self).__init__()\n        self.conv1 = nn.Conv3d(in_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn1 = nn.BatchNorm3d(32)\n        self.relu = nn.ReLU()\n        \n        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn2 = nn.BatchNorm3d(64)\n        \n        self.pool_time = nn.AdaptiveAvgPool3d((1, None, None))\n        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.pool_time(x).squeeze(2)\n        x = self.final_conv(x)\n        return x\n\n\nclass AvalancheNet_Medium(nn.Module):\n    \"\"\"Medium model with dropout regularization - 32â†’64 filters + dropout\"\"\"\n    def __init__(self, in_channels, num_classes, dropout_rate=0.3):\n        super(AvalancheNet_Medium, self).__init__()\n        self.conv1 = nn.Conv3d(in_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn1 = nn.BatchNorm3d(32)\n        self.relu = nn.ReLU()\n        self.dropout1 = nn.Dropout3d(p=dropout_rate)\n        \n        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn2 = nn.BatchNorm3d(64)\n        self.dropout2 = nn.Dropout3d(p=dropout_rate)\n        \n        self.pool_time = nn.AdaptiveAvgPool3d((1, None, None))\n        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.dropout1(x)\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.dropout2(x)\n        x = self.pool_time(x).squeeze(2)\n        x = self.final_conv(x)\n        return x\n\n\nclass AvalancheNet_Deep(nn.Module):\n    \"\"\"Deeper model - 3 conv layers, 64â†’128â†’128 filters\"\"\"\n    def __init__(self, in_channels, num_classes):\n        super(AvalancheNet_Deep, self).__init__()\n        self.conv1 = nn.Conv3d(in_channels, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn1 = nn.BatchNorm3d(64)\n        self.relu = nn.ReLU()\n        \n        self.conv2 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn2 = nn.BatchNorm3d(128)\n        \n        self.conv3 = nn.Conv3d(128, 128, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn3 = nn.BatchNorm3d(128)\n        \n        self.pool_time = nn.AdaptiveAvgPool3d((1, None, None))\n        self.final_conv = nn.Conv2d(128, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.relu(self.bn3(self.conv3(x)))\n        x = self.pool_time(x).squeeze(2)\n        x = self.final_conv(x)\n        return x\n\n\nclass AvalancheNet_MaxPool(nn.Module):\n    \"\"\"Uses MaxPooling instead of AvgPooling - captures extreme events\"\"\"\n    def __init__(self, in_channels, num_classes):\n        super(AvalancheNet_MaxPool, self).__init__()\n        self.conv1 = nn.Conv3d(in_channels, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn1 = nn.BatchNorm3d(32)\n        self.relu = nn.ReLU()\n        \n        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1))\n        self.bn2 = nn.BatchNorm3d(64)\n        \n        # Key difference: MaxPooling captures peak conditions over 7 days\n        self.pool_time = nn.MaxPool3d((7, 1, 1))\n        \n        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x = self.relu(self.bn1(self.conv1(x)))\n        x = self.relu(self.bn2(self.conv2(x)))\n        x = self.pool_time(x).squeeze(2)\n        x = self.final_conv(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.741241Z","iopub.execute_input":"2025-12-04T12:19:26.741405Z","iopub.status.idle":"2025-12-04T12:19:26.764148Z","shell.execute_reply.started":"2025-12-04T12:19:26.741392Z","shell.execute_reply":"2025-12-04T12:19:26.763694Z"}},"outputs":[],"execution_count":11},{"id":"4e28119c","cell_type":"markdown","source":"## Advanced Architectures\n\nThese models address deeper spatial patterns and temporal sequence modeling:\n1. **DeepAvalancheNet**: 4-layer deep CNN with downsampling and upsampling for better spatial feature extraction\n2. **AvalancheConvLSTM**: ConvLSTM for capturing temporal evolution (e.g., storm â†’ settling transitions)","metadata":{}},{"id":"e2a8fa4d","cell_type":"code","source":"class DeepAvalancheNet(nn.Module):\n    \"\"\"\n    Improved 3D CNN: Deeper (4 layers) to capture larger spatial patterns.\n    Includes Dropout for regularization and spatial downsampling/upsampling.\n    \"\"\"\n    def __init__(self, in_channels, num_classes):\n        super(DeepAvalancheNet, self).__init__()\n        \n        # Block 1: Low-level features (e.g., local snow/wind gradients)\n        self.layer1 = nn.Sequential(\n            nn.Conv3d(in_channels, 32, kernel_size=3, padding=1),\n            nn.BatchNorm3d(32),\n            nn.ReLU(),\n            nn.Dropout3d(0.2)\n        )\n        \n        # Block 2\n        self.layer2 = nn.Sequential(\n            nn.Conv3d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm3d(64),\n            nn.ReLU(),\n            nn.MaxPool3d((1, 2, 2)),  # Downsample H/W only, keep Time\n            nn.Dropout3d(0.2)\n        )\n        \n        # Block 3: Mid-level features (e.g., regional patterns)\n        self.layer3 = nn.Sequential(\n            nn.Conv3d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm3d(128),\n            nn.ReLU(),\n            nn.Dropout3d(0.3)\n        )\n        \n        # Block 4: High-level features\n        self.layer4 = nn.Sequential(\n            nn.Conv3d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm3d(256),\n            nn.ReLU(),\n            nn.MaxPool3d((1, 2, 2)), \n            nn.Dropout3d(0.3)\n        )\n        \n        # Aggregate Time: Average over the 7-day window\n        self.pool_time = nn.AdaptiveAvgPool3d((1, None, None))\n        \n        # Upsample back to original map size (Segmentation logic)\n        self.upsample = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n        \n        # Final Classification\n        self.final_conv = nn.Conv2d(256, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        # Input: (B, C, T, H, W)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        # Collapse Time: (B, 256, 1, H/4, W/4) -> (B, 256, H/4, W/4)\n        x = self.pool_time(x).squeeze(2)\n        \n        # Restore Resolution: (B, 256, H, W)\n        x = self.upsample(x)\n        \n        # Classify\n        x = self.final_conv(x)\n        return x\n\n\nclass AvalancheConvLSTM(nn.Module):\n    \"\"\"\n    ConvLSTM: Captures temporal sequence evolution (e.g., Storm -> Settling).\n    Better for 'Transition Days' where temporal dynamics matter.\n    \"\"\"\n    def __init__(self, in_channels, num_classes, hidden_dim=64):\n        super(AvalancheConvLSTM, self).__init__()\n        \n        self.hidden_dim = hidden_dim\n        \n        # Feature Extractor (Spatial)\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, hidden_dim, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        \n        # LSTM Cell (Temporal)\n        # Simplified implementation: treating Time as Batch dim for Conv, then looping\n        self.lstm_conv = nn.Conv2d(hidden_dim * 2, hidden_dim * 4, kernel_size=3, padding=1)\n        \n        self.final = nn.Conv2d(hidden_dim, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        # Input: (B, C, T, H, W)\n        b, c, t, h, w = x.size()\n        \n        # 1. Fold Time into Batch to process spatial features in parallel\n        # (B*T, C, H, W)\n        x_time_flat = x.permute(0, 2, 1, 3, 4).contiguous().view(b * t, c, h, w)\n        \n        # Extract features\n        features = self.conv(x_time_flat)\n        \n        # Unfold Time: (B, T, Hidden, H, W)\n        features = features.view(b, t, self.hidden_dim, h, w)\n        \n        # 2. Manual ConvLSTM Step (Last Day Prediction)\n        # Initialize hidden state (h) and cell state (c)\n        h = torch.zeros(b, self.hidden_dim, h, w).to(x.device)\n        c = torch.zeros(b, self.hidden_dim, h, w).to(x.device)\n        \n        # Iterate through time steps\n        for i in range(t):\n            xt = features[:, i, :, :, :]\n            combined = torch.cat([xt, h], dim=1)\n            \n            # Gates (Input, Forget, Output, Cell)\n            gates = self.lstm_conv(combined)\n            ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n            \n            ingate = torch.sigmoid(ingate)\n            forgetgate = torch.sigmoid(forgetgate)\n            cellgate = torch.tanh(cellgate)\n            outgate = torch.sigmoid(outgate)\n            \n            c = (forgetgate * c) + (ingate * cellgate)\n            h = outgate * torch.tanh(c)\n            \n        # 3. Final Prediction based on last hidden state\n        out = self.final(h)\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.766638Z","iopub.execute_input":"2025-12-04T12:19:26.767043Z","iopub.status.idle":"2025-12-04T12:19:26.786028Z","shell.execute_reply.started":"2025-12-04T12:19:26.767028Z","shell.execute_reply":"2025-12-04T12:19:26.785437Z"}},"outputs":[],"execution_count":12},{"id":"28e53a30","cell_type":"markdown","source":"### How to Use Advanced Models\n\nYou can easily switch between architectures in the model initialization cell:\n\n````python\n# Option 1: Deep 3D CNN (Recommended for spatial patterns)\nmodel = DeepAvalancheNet(in_channels=len(dynamic_features)+4, num_classes=5).to(device)\n\n# Option 2: ConvLSTM (Best for temporal transitions)\nmodel = AvalancheConvLSTM(in_channels=len(dynamic_features)+4, num_classes=5).to(device)\n````\n\n**DeepAvalancheNet** benefits:\n- 4 convolutional layers capture hierarchical spatial patterns\n- Downsampling (2x2) increases receptive field\n- Upsampling restores full resolution for pixel-wise classification\n- Better for capturing regional avalanche patterns\n\n**AvalancheConvLSTM** benefits:\n- Models temporal evolution across the 7-day sequence\n- Captures storm â†’ settling transitions\n- Better for days with rapid weather changes\n- Each time step influences the next (not just aggregation)","metadata":{}},{"id":"d7fedafe","cell_type":"code","source":"def calculate_metrics(model, dataloader, device, criterion):\n    \"\"\"\n    Calculate validation metrics including Macro-F1 score.\n    \n    Returns:\n        dict: Contains loss, macro_f1, and per-class F1 scores\n    \"\"\"\n    model.eval()\n    all_preds = []\n    all_targets = []\n    total_loss = 0\n    \n    with torch.no_grad():\n        for x, y in dataloader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            loss = criterion(outputs, y)\n            total_loss += loss.item()\n            \n            # Get predictions (argmax over class dimension)\n            preds = torch.argmax(outputs, dim=1)\n            \n            # Flatten spatial dimensions and filter out ignore_index (0)\n            preds_flat = preds.cpu().numpy().flatten()\n            targets_flat = y.cpu().numpy().flatten()\n            \n            # Only keep non-zero labels (ignore background)\n            mask = targets_flat != 0\n            preds_flat = preds_flat[mask]\n            targets_flat = targets_flat[mask]\n            \n            all_preds.extend(preds_flat)\n            all_targets.extend(targets_flat)\n    \n    avg_loss = total_loss / len(dataloader)\n    \n    # Calculate Macro-F1 (average F1 across classes 1-4)\n    macro_f1 = f1_score(all_targets, all_preds, average='macro', labels=[1, 2, 3, 4], zero_division=0)\n    \n    # Per-class F1 scores\n    per_class_f1 = f1_score(all_targets, all_preds, average=None, labels=[1, 2, 3, 4], zero_division=0)\n    \n    return {\n        'loss': avg_loss,\n        'macro_f1': macro_f1,\n        'f1_class_1': per_class_f1[0],\n        'f1_class_2': per_class_f1[1],\n        'f1_class_3': per_class_f1[2],\n        'f1_class_4': per_class_f1[3]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.786866Z","iopub.execute_input":"2025-12-04T12:19:26.787061Z","iopub.status.idle":"2025-12-04T12:19:26.806003Z","shell.execute_reply.started":"2025-12-04T12:19:26.787047Z","shell.execute_reply":"2025-12-04T12:19:26.805392Z"}},"outputs":[],"execution_count":13},{"id":"c2d1651f","cell_type":"markdown","source":"Now, from the EDA we know that we are dealing with a highly imbalanced dataset. To tackle this, we will implement a weighted cross-entropy loss function that assigns higher weights to the minority classes. This approach will help the model pay more attention to underrepresented classes during training. We create training and test sets and use ADAM optimizer for training the CNN model.\n\n![image.png](attachment:image.png)","metadata":{},"attachments":{"image.png":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQoAAAB1CAYAAAC2yK9pAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAABV8SURBVHhe7d1fSCPX2wfw7+99cQtJusoaV7smbAKtLSTKXFTqXZGwEBjsTW4CKg1eeVUEdyF0Ed7FbhHWBd0roSCCuxCkoRciSJcghRaE3ExXhbJ7YUrc1jRxsSW6RQvve/HmHGZOMnNmkvhnt88HvDAnZ3LmZPLknMmZZ/5z8+bN/wUhhFj4L/EBQggRUaAghEhRoCCESFGgIIRIOQoUiqJgeXkZiURCLLqULrq9qqoilUohnU4jnU5fWDsIaZSjQEGcWVtbQzwex/T0NI6Pj8ViQt4YFCgIIVL/ka2jSCQSGBoaMjy2urqKpaWlmuW7u7u4ffs2ACCZTMLr9aJUKqG/v7+qnD2HlTHHx8d4+PAhNE2r2r7+tVVVRSwWQzqdRjweh8vlMtRVFAWTk5PIZDK8jshs+6zuzs4OZmZmeHkymUQoFLLVPsZOOwi5zCxHFIlEAtFoFIuLi4jFYlVDaEVRcPPmTcRiMcRiMSwuLsLn8xnm4sFgEF6vt2Z5IpGAoih8+6urq1VBQv/6i4uLiEajhu27XC6MjY0hk8kgFouhUChgZGSEl1ux2r6madjZ2UEgEIDf7wcA+P1+BAIB7Ozs2G4fIW8Dy0ARDoehaRrW1tbEIgCApmm4d+8e///Zs2c4PDxEV1cXf6xYLGJ+fr5meVdXF/b29vj2NU3D6ekpuru7gRqvv7a2hr29PYTDYb59CN/ipVIJHo+Hf7ityLa/tbUFt9uNvr4+AEBfXx+uXLmC9fV1W/UJeVuYBgq/3w+PxyM+XGV2dpaf1Z+bm0NHR4f4FFP7+/vw+XxQVRUAEI1G0dLSgpcvX/LX7+/v59tPp9MIBoOGbZyenqJYLPL/Z2ZmMD4+jnw+b3ieyM7219bWUCgU0NvbCwDo7e3Fq1evoGmarfqEvC1MA4UdyWQSnZ2dmJ6eRiwWw8TEhOFDa0dLSwvGxsaQTqehKApSqRQ0TUM+n0e5XEY2m+VTG/anP8dRL7vb397eRiAQgKIouHHjBjY2NhzVJ+RtYBoo8vk8crkcn6OzE3Iul4s/x+v14ujoCAcHBwCA4eFhRyOKcDhs+KDF43HDNGd7exuKovARR7PZ2X4mk8HJyQkGBweByvSJsVOfkLeB5a8efr8fd+/e5R/+p0+fQlEUbG5uGn4ZYMFjd3cXqJwnmJmZQTKZRCAQwP3795HP5/n2crkcZmZmoKoqRkdH0dLSYnhdq19V9OWqqiIejyOVStU8jyK2j8lms/yXDKvtM+yXGfFxSOrX+kUHwusT8iawDBRnSQwajPjzIyHk4plOPc5ae3s73G63+HDVdIYQcvEubESByoIpcepRLBb5VIUQcjlcaKAghLwZLmzqQQh5c1CgIIRIUaAghEhRoCCESFGgIIRIUaAghEhJfx6dnZ3lV0Tqc0XYJS5xrrUM+iI1q31suXat5dlmZeI6ktPTUywvL1ctR6+3fq0l7PXuH/l3sxxRsAQs7KKtQqGA8fFxW7keUDmQI5GIITFNNBq9NBdRNat9qqoiFApV5cX0+/1YWFjA1atXq8qgy6nJ+lfTNAwNDRkS5TRSX9M0jI6O8vLV1VVEIhEoiiJuihBLloFiaWnJcMn0xsaGIZGLzODgIAqFAv+Gy2QyODw85FdiXrRmtW9wcBA7OzsoFAqGx4eHh7G5uYmVlRXD42b29/fhdrvR3t4ONKG+iKUAYImBCLHLMlA0QlEUdHZ2Ynt7mz8WiUTQ0dFhOwPVWWpW+xKJBDo7O3nWK72ZmRlHw/xwOIxCocCndo3WF/X29uLo6MhwqTwhdjgKFIODg44ONH32qdnZWQwMDODp06eW33rnqdH2+f1+DAwMIJPJmH44ZRKJBM+O5fF4eNpAu2T19fcWCYVCWFhYoOtoiGO2A0UikUAwGMTm5qajA62jowPLy8solUoYHx/H33//famuDm2kfcPDw0BlylKvpaUlfg5hc3MTDx48cHSORFZffx4jlUohmUxS8l/imK1AwX4ZyGazjobCLS0tiEajSKVS/Gy9PvHuRWukfYqioKenB6urq44CpxV2joTl6HRKVp+S/5J6SQOFqqqIRqNVP83JaJqGQqFgyLKNSr6JXC7XtA9XvRptn6IoaG1t5fk+WWLd/v5+pFIpR6MC0f7+vviQI7L6pVJJfIgQS5aBQlEUxONx7O3tWQYJlok7mUwaHt/e3kYwGORD3UQiAZ/Ph62tLcPzLord9tXaP/2Qn/3t7u4im81W5f60a3h4GG63u+7zHbL6ZvtHiIzlgiv9Yis98W5f7Hm1Rh36BU3igqDLwE77rPZPb3Z2lucLRY3FXAzrPzGnppi0p9n161kwRwhkgYIQQiCbehBCCChQEELsoEBBCJGiQEEIkaJAQQiRokBBCJGiQEEIkaJAQQiRokBBCJGyXJkpy8loh7iM+LLlbGykfbL+EctRYxm1uAxbXB4va5+snGHPE7dPiB3/3dbW9j/ig8yLFy/w7bffYmVlBSsrK3j//ffxySef4Oeff8Zff/0lPr2Kqqr47LPPsLy8jK+++goulwvRaBSvX7/GixcvxKefu0bbJ+ufnp4efPDBB3jw4AEePXqElZUVfPfdd/zqzmQyiUAggLt37+Kbb77B8+fPcevWLXz44Yf48ccfpe2TlTOKomB4eBjHx8d4/fo1vv/+e91eECLnaOohy8koalZOyrPS7PY57R+v14tyucwv4jo4OMDR0REvl7VPVs5Eo1EUCgU8f/7c8DghdjkKFLKcjHrNykl5Vs6ifU76B5VkxT6fD7Ozs4DuMvH19XVp+27dumVZztrPMoRvbGzw5xHilDRQJCQ5Ga00mpPyrDWjfbL+cblcmJqa4s9huS9QyTh1584deDwepNNpBAIBfPnllzzQWLXv6tWrluWs/SxDuJPzSoSIpIFClpNRppGclOeh0fZZ9Y8+XyW7r8bQ0BAPFoqi4Ouvv0a5XMbExAQAVPWvWfvYOSKz8oODAyQsMoQT4oQ0UOjJcjKKGslJeR6a3T5Z/2QyGRSLRf4aIyMjODo6wvz8PPL5PO7fv284xyBrn1V5V1dXwxnCCWEcBQpGlpMRTchJedbOsn1m/dPe3g632w1UUv17PB7Dycx8Po9yuQzYaN/Tp08ty69fv462tjYMDQ3xaU9/fz+CwWDVFIgQGUeBwiwnY62cknCQk/Ki2G2f2f6JzPqHGRkZAQCsr68jn88jl8uhs7OT3+JPVVX4fD6e/FbWPqtycdoTi8WQzWaxu7uLWCxWc60FIWYsF1yJi4HEnIyMVU5J/YIgcUHSZWCnfWb7J+sf/bZRYzEVauQlFV9D1j5ZuV4ymYTX661qAyEyloGCEELgdOpBCPl3okBBCJGiQEEIkaJAQQiRokBBCJGiQEEIkaJAQQiRokBBCJGyteCKrUAUVw3aIa5ONEvVdlEabZ9+ZaWY5o6R9V+95WKqPXFlpqIomJychMvl4nWc7h8hkI0o/H4/FhYWcPXqVRwfH4vFUqqqIhKJYHFxkV9mHY1GHV2mfpYabR+7xoJdS1EoFDA+Ps6Txsj6r9Fy8XoOTdMwNDTEX1/TNIyOjhouc49EIvzaEkLssgwUw8PD2NzcxMrKilhki91UbRel0fYtLS0ZrpvY2NiA2+1GX18fYKP/Gi0XyVLxsSQ33d3dYhEhliwDxczMTN3DVFkqt3pSzTXTebRP1n+Nlotkqfh6e3txdHSEZ8+eiUWEWLIMFI2yk6rtIjW7fYODg+f+QUxIUvGpqopUKoV0Oo1QKISFhYWqq38JkTnTQAFJqrbLoFntSyQSCAaD2NzcPNcPolUqPgjnMVKpFJLJJD+3QohdZxoorFK1XQbNah/75SSbzTqaKjSbLBXf2toa9vb2EA6HxSJCLJ1ZoJClcjvPb91amtU+VVURjUarfrq8SGap+BiWQYsQu5oSKMxSxVmlarsM7LbPbP8URUE8Hsfe3t6lCBKyVHxm+0eIjOWCK3ExEiOmdDNLFQeHqdougp32me2fmMaOYf0j679Gy52m4jNbEEaIjGWgIIQQNGvqQQh5u1GgIIRIUaAghEhRoCCESFGgIIRIUaAghEhRoCCESFGgIIRIUaAghEjZXplplrdRRlxGfNlyNjbaPjv1a/Wd3+/H3bt30dHRYXguKku05+fnLcvZEnpZzk477SNExtaIQlVVhEKhmnkbrTSak/KsNdo+WX2rnJf5fB7j4+M8l0QsFsPExASKxSJKpZK0HDZydiYSCUSjUd6+xcVFRCIR2/tHCGMrUAwODmJnZweFQkEsstRoTsqz1mj7ZPWd5ryMRCJwu91YX18Xi4Aa5bKcneFw2HAZ/draGgqFgu39I4SRBopEIoHOzk7Tg9fMeeSkbESj7bNT30nOS7/fj4GBAdOcl7JyM2LuiVKpZGv/CNGzDBTs4MxkMo4OTqbZOSmbrdH2NVpfr6+vD263GxsbG2IRYKMcNXJ2lkolhEIhnp5fURSEQiGhFiFyloFieHgYqAyp69WsnJRnpdH2NVqfEacxIll5okbOzpmZGRQKBUxNTSGdTmNyctJ25i5C9EwDhaIo6Onpwerqat0HV7NyUp6VRtvXaH1GVVV0dnaajhZk5eyXjVo5O2/fvs1Pdo6OjuLKlSsol8t1v6fk38kyULS2tmJsbIyngw8Gg+jv70cqlZKeOW9WTsqz0mj7Gq2vJ04ZRFblTnJ21jqvQogdpoFCnwae/e3u7iKbzSIejxs+HGY5Je3mpLwodtt3lvvHPrxmaf6typ3k7GT3IS0UClWjDkJkbC+4QuUDUyqVqg5Ks5ySsJmT8iLZaV+9+ycudmLEBVMej8eQ61LPqlyWs1MVbmJMi61IvRwFCkLIv5Pp1IMQQhgKFIQQKQoUhBApChSEECkKFIQQKQoUhBApChSEECkKFIQQKQoUhBAp05WZLKdjW1ubYVlyMpmE1+s1ZFYiF4stFb/sS7TZMZXL5aqWwr/pWF5U6Jbyv3z5EpOTk3C5XABQ8xKA8yDmZ9VfQsCwa4EAVOVdhZ0RxfHxMXp7e8WHyTlRVRXLy8vSq3XfVIqiYHl5mV9Y9yZKJBJQFIXnJmUXTWqahtHRUZ7r9CzI+k9VVTx48AC5XI5f3CkGCQAYGRkBKkGuFmmg2N/fRyAQ4FmSyOXDrvS9zKOJt1lXVxcODw9rpgG4aIODg9A0zXIko6oqrl27ZpmgSjr1yOVy8Hq92N7extLSUtXUQ7xCkg1rFEXBF198gV9//RV9fX0oFov4/fff0dfXZxj6iPVrDZ/ZsK5WmRXW1lKpxIeFxWKRX4mpqipisRjS6TTi8ThcLldVynv9kBLC8FG2fVl9q9fv7u42XPmpx7Zh5+pQsX/Fvh8YGICmabh16xZQo/2NEtuISvvX19cNw3I9/e0KyuWy4RswkUggEong4cOHUBSlqv3i+ye+fq3hP+ujWmV2JJNJBAIB036zmnJZvT+o0X72/rS3t1v2n/4zmE6nq66IZvRt29raQiwWw6NHj5xPPVDJ7tzT0yM+DEVRcPPmTT6kWVxchM/n48OglpYWvPfee1hZWUFbWxveffddrK6uorOzE4qiIFEjnXw0GjUdRtUjGAzC6/UiFothenoabrebp/gDAJfLhbGxMWQyGcQqKe/ZMCyZTCIUCmF6eprXD4VChrwUVtu3U9/s9dfW1hCPx7G4uIjj42PeR7FYjB9s7DnT09NVtwNA5SDU9+/ExAQ8Hg9mZ2f5czo6OqAoCiYmJqra3yh2kK+vr/PXZ0NwNixnbV9dXeX7d/v2beTzeWxubvJjBbocrjs7O/xA1rd/YmICR0dH/P0TX79W/9eL3YohnU6jv78fHR0dmJubQzqdNvSvFdn74/f78fHHH+POnTtVx5es/wCgu7sbANDT08OTT4lJpyKRCADgyZMn/LFabAWKZ8+ewePxVM2TNU3DvXv3DM87PDw0pIPb3NxEuVzG6ekpNjY2UCwW+TwoHA5D0zRDOvm9vT2Ew2FeH5Xcj7E6h9bFYhHz8/NApb07Ozvwer2G5+i/iVmW6v7+fgQCAcNByeoHAgGexdps+36/31Z9s9dvRpZsMV1/rQ/f8fExFhYWkM/noVWydon9U6/e3l7s7e3V9b6h0l+ofCFBl2BYnxhI3362f6z/xNc36382dRO/7a3kdfddyWazKBaLmJiYMHxQZWTvTz6fx7179/gopZ73x+Vyobu7mwcRTdMQj8ehKAoURUEkEqmZFElkK1Dk83n89ttvNU9qsuxP6XQac3NzNe9sVcv169f5B5LVZ+n2zpr+g6jPpI1KUBofH8fp6Sncbjf29/d1Nf//nI0sy7bH48FHH31kq77Z68veOBm/3w+Px1OVrp+9Fvu2OUtODuha2AebfXH09vZaJhhmWP96vV4Eg0HD8aWfBl4ku+9PMpls6PNxfHyMx48f8//ZbTcURUE0GrWd8cxWoEDlBbxeL9555x3+WDKZRGdnJx9aOzm7+8cff6BcLiObzfJoJw6dzoLX67WVXPbg4ABHR0dVyXK7uross2yz7f/yyy911W+WfD6Pcrlc9WFlgfzly5eGxy+rra0tXLt2DZ9++ilu3LhhmmCY0fdvqVTC7u5u1fHVjEDcKDvvj/hrSqySjtIu9h6LXwqnp6f4559/EAgEDIF0bGwMra2tmJqaqpo+2Q4Umqbh5OTE8E3q9XoNB/3w8LDtEQUqOScVRama0ohYVG303IWqqvD5fLaSy+bzeeRyOcN9MVRVhaIopkM1/fbrqV8Le7NrjeZktre34fP5eP+yoaZ+OmQH63+nc/vt7W0+jBZ/y2dYQBanm8za2hpevXqFzz//HCcnJ5ajCaVy3xKW3Hhra8twzsxMIpGoa/8aJXt/urq6cHp6yo+BROWWDHpW/adpGl69emW4M1w0GsXJyQl++OGHqltWLi4u4s8//8T09HTVl7XtQAEAP/30E65fv87/f/z4MdxuNz+J4/V6HUW8paUlrK+vGzJ9NyMg6OlPMo2OjmJ5ednWUAs17osxNjaG9fV1Q32r7dupL6NpGjKZjGGKxg5o9gGempqCy+XC0NCQoXxpaQmapvH+nZqaws7OjqO5OCrf6qenp4agZ8fS0hLf/7m5OeRyuarjI5/PY3V1FT6fj++f+G22vb2N1tbWmgHe5XLx/p2amkImkzGc7F1eXkY0GjUcX+cVEFgAYlNy9h6y/ZO9P0+ePMHR0RHfv4GBgaqfYGX9Nz8/D4/Hw8usfp2xYvrz6NtA9rNVo856+5cFGw0AuJB91f8kqh8JmT1Oms/RiIL8O7F7qjq9X0kzsOF4vbe1JM1BgYKYYmsF2HUkTqcsjVBVFalUig/HnUzXSPP9H4A8VsZre2JFAAAAAElFTkSuQmCC"}}},{"id":"31584074","cell_type":"markdown","source":"### Model Architecture Summary\n\n**Input Tensor Shape**: `(Batch=4, Channels=15, Time=7, Height=211, Width=470)`\n- **11 dynamic features** (weather/snow conditions over 7 days)\n- **4 static features** (terrain: elevation, slope, aspect_sin, aspect_cos)\n\n**3D CNN Processing**:\n1. Conv3D layer 1: Extracts spatio-temporal patterns â†’ 32 filters\n2. Conv3D layer 2: Deeper features â†’ 64 filters  \n3. Temporal pooling: Aggregates 7 days into single time step\n4. Conv2D output: Maps to 5 danger level classes per pixel\n\n**Output**: `(Batch=4, Classes=5, Height=211, Width=470)` - Danger level prediction for each grid cell","metadata":{}},{"id":"a0bb6bc8","cell_type":"markdown","source":"## 2-3 Week Training Plan\n\n**Week 1: Architecture Search (4 runs Ã— 5 epochs â‰ˆ 8-12 hours)**\n- Test Light, Medium, Deep, MaxPool variants\n- Identify best architecture based on validation loss\n\n**Week 2: Hyperparameter Tuning (6 runs Ã— 10 epochs â‰ˆ 20-25 hours)**\n- Test 3 learning rates on best architecture\n- Test 3 dropout rates for regularization\n\n**Week 3: Final Training (2 runs Ã— 20 epochs â‰ˆ 12-16 hours)**\n- Train best model with optimal hyperparameters\n- Full 20-30 epoch training for final evaluation\n\n**Total: ~40-50 GPU hours on Kaggle (well within 30 hours/week limit)**","metadata":{}},{"id":"526cec5b","cell_type":"code","source":"# --- FIX 3: Class Weights for Imbalance ---\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# 1. Print class distribution\nif 'danger_level' in train_df_subset.columns:\n    freq_dangerLevel = train_df_subset['danger_level'].value_counts(normalize=True).sort_index()\n    print(f\"Class Distribution in Training Data:\\n{freq_dangerLevel}\\n\")\n    \n    # Calculate weights based on training labels\n    y_train_labels = train_df_subset['danger_level'].values.astype(int)\n    classes = np.unique(y_train_labels)\n    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_labels)\n    \n    # Convert to Tensor (Index 0 is 'No Data', mapped to weight 0)\n    # Classes in data are 1, 2, 3, 4. Indices in tensor are 0, 1, 2, 3, 4.\n    final_weights = torch.tensor([0.0] + list(weights), dtype=torch.float32)\n    \n    print(f\"Class Weights (balanced): {final_weights}\")\nelse:\n    # Fallback: Use inverse frequency from original distribution\n    class_counts = torch.tensor([\n        0.0,      # Class 0 (NoData) - will be ignored anyway\n        0.211133, # Class 1\n        0.413133, # Class 2\n        0.358004, # Class 3\n        0.017729  # Class 4 \n    ], dtype=torch.float32)\n    \n    final_weights = torch.zeros(5, dtype=torch.float32)\n    final_weights[1:] = 1.0 / class_counts[1:]\n    final_weights = final_weights / final_weights[1:].sum()\n    print(f\"Class Weights (inverse frequency): {final_weights}\")\n\n# 2. Instantiate Datasets\ntrain_ds = AvalancheDataset(train_dates, dynamic_dir, target_dir, static_file, stats, dynamic_features)\nval_ds = AvalancheDataset(val_dates, dynamic_dir, target_dir, static_file, stats, dynamic_features)\n\n# Use num_workers for faster data loading (Kaggle optimization)\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, \n                          num_workers=2, pin_memory=True, persistent_workers=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n                        num_workers=2, pin_memory=True, persistent_workers=True)\n\n# 3. Initialize Model\n# Input channels = 11 dynamic + 4 static = 15\nmodel = AvalancheNet(in_channels=len(dynamic_features)+4, num_classes=5).to(device)\n\n# 4. Loss Function with Class Weights\ncriterion = nn.CrossEntropyLoss(weight=final_weights.to(device), ignore_index=0)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Add Scheduler (Optional but recommended)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2, factor=0.5)\n\nprint(\"\\nâœ… Model, DataLoaders, and Weighted Loss Function ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:26.806650Z","iopub.execute_input":"2025-12-04T12:19:26.806865Z","iopub.status.idle":"2025-12-04T12:19:29.714257Z","shell.execute_reply.started":"2025-12-04T12:19:26.806846Z","shell.execute_reply":"2025-12-04T12:19:29.713546Z"}},"outputs":[{"name":"stdout","text":"Class Weights (inverse frequency): tensor([0.0000, 0.0714, 0.0365, 0.0421, 0.8500])\nDataset initialized. EXPECTING Shape: (211, 470, 11)\nDataset initialized. EXPECTING Shape: (211, 470, 11)\n\nâœ… Model, DataLoaders, and Weighted Loss Function ready.\n","output_type":"stream"}],"execution_count":14},{"id":"5d7e3c30","cell_type":"markdown","source":"## WEEK 1: Architecture Search\n\nRun this cell to compare all 4 architectures with 5 epochs each.","metadata":{}},{"id":"adbe9ff2","cell_type":"markdown","source":"## Robust Training Loop with Checkpoints\n\nThis training loop includes:\n- **Checkpoint saving/resuming**: Prevents data loss from crashes\n- **Macro-F1 tracking**: Primary metric for imbalanced data\n- **Early stopping**: Stops when validation performance plateaus\n- **Mixed precision**: Faster training on GPU","metadata":{}},{"id":"6464dc5d-adb6-4aae-9f94-0b4b314610c4","cell_type":"code","source":"import torch\nimport numpy as np\n\nprint(\"--- 1. GPU CHECK ---\")\nprint(f\"Is CUDA available? {torch.cuda.is_available()}\")\nif not torch.cuda.is_available():\n    print(\"âš ï¸ WARNING: You are STILL on CPU. Did you restart the session after changing settings?\")\n\nprint(\"\\n--- 2. STATS CHECK (The likely culprit) ---\")\n# Check if your normalization statistics are corrupted\npoison_stats = False\nfor feat, stat in stats.items():\n    mu = stat['mean']\n    sigma = stat['std']\n    if np.isnan(mu) or np.isnan(sigma) or sigma == 0:\n        print(f\"âŒ POISON DETECTED in feature '{feat}': Mean={mu}, Std={sigma}\")\n        poison_stats = True\n\nif not poison_stats:\n    print(\"âœ… Normalization stats look healthy.\")\nelse:\n    print(\"ğŸ›‘ STOP: You cannot train with NaN statistics. Fix your dataframe or feature calculation.\")\n\nprint(\"\\n--- 3. DATA LOADER CHECK ---\")\n# Grab one batch to check what is actually being fed to the model\ntry:\n    # Re-initialize loader to be safe\n    dataset_check = AvalancheDataset(train_dates[:100], dynamic_dir, target_dir, static_file, stats, dynamic_features)\n    loader_check = DataLoader(dataset_check, batch_size=4, shuffle=True)\n    \n    X_batch, Y_batch = next(iter(loader_check))\n    \n    print(f\"Batch X Stats: Min={X_batch.min():.4f}, Max={X_batch.max():.4f}, Mean={X_batch.mean():.4f}\")\n    \n    if torch.isnan(X_batch).any():\n        print(\"âŒ CRITICAL: Input Batch contains NaNs! The model will fail immediately.\")\n    else:\n        print(\"âœ… Input Batch is clean (No NaNs).\")\n        \n    print(f\"Batch Y Unique Values: {torch.unique(Y_batch)}\")\n    \nexcept Exception as e:\n    print(f\"âŒ Loader crashed during check: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:29.715027Z","iopub.execute_input":"2025-12-04T12:19:29.715402Z","iopub.status.idle":"2025-12-04T12:19:31.009068Z","shell.execute_reply.started":"2025-12-04T12:19:29.715384Z","shell.execute_reply":"2025-12-04T12:19:31.008346Z"}},"outputs":[{"name":"stdout","text":"--- 1. GPU CHECK ---\nIs CUDA available? True\n\n--- 2. STATS CHECK (The likely culprit) ---\nâœ… Normalization stats look healthy.\n\n--- 3. DATA LOADER CHECK ---\nDataset initialized. EXPECTING Shape: (211, 470, 11)\nBatch X Stats: Min=-18.3250, Max=1897.4150, Mean=28.5845\nâœ… Input Batch is clean (No NaNs).\nBatch Y Unique Values: tensor([0, 1, 2, 3, 4])\n","output_type":"stream"}],"execution_count":15},{"id":"62a8bfad-7f41-4b34-b08a-def7ab2c5d0f","cell_type":"code","source":"print(\"scanning for valid targets...\")\nfound_valid_classes = set()\nbatches_checked = 0\n\n# Scan 100 batches (400 samples)\nfor X, Y in tqdm(train_loader, total=100):\n    unique_labels = torch.unique(Y).tolist()\n    found_valid_classes.update(unique_labels)\n    \n    if len(found_valid_classes) > 1: # We found something other than 0\n        print(f\"âœ… SUCCESS: Found valid classes: {found_valid_classes}\")\n        break\n    \n    batches_checked += 1\n    if batches_checked >= 100:\n        break\n\nif len(found_valid_classes) <= 1:\n    print(\"\\nâŒ CRITICAL FAILURE: Only found Class 0 (Background) after scanning 400 samples.\")\n    print(\"Your Target Rasterization (Script 3) likely generated empty black images.\")\n    print(\"Check: Did you flip the coordinates correctly? Do the polygon IDs match?\")\nelse:\n    print(\"\\nâœ… Data looks good! You are ready to train.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:31.009970Z","iopub.execute_input":"2025-12-04T12:19:31.010329Z","iopub.status.idle":"2025-12-04T12:19:32.808857Z","shell.execute_reply.started":"2025-12-04T12:19:31.010302Z","shell.execute_reply":"2025-12-04T12:19:32.807871Z"}},"outputs":[{"name":"stdout","text":"scanning for valid targets...\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/100 [00:01<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"âœ… SUCCESS: Found valid classes: {0, 1, 2, 3}\n\nâœ… Data looks good! You are ready to train.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":16},{"id":"06587293","cell_type":"code","source":"import time\n\n# Checkpoint Configuration\nCHECKPOINT_DIR = 'models/checkpoints'\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nBEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, 'best_cnn_model.pth')\nLAST_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, 'last_checkpoint.pth')\n\n# Helper to save checkpoint\ndef save_checkpoint(state, is_best, filename):\n    torch.save(state, filename)\n    if is_best:\n        torch.save(state, BEST_MODEL_PATH)\n        print(f\"  ğŸ”¥ New Best Model saved to {BEST_MODEL_PATH}\")\n\n# --- RESUME LOGIC ---\nstart_epoch = 0\nbest_val_f1 = 0.0\n\nif os.path.exists(LAST_CHECKPOINT_PATH):\n    print(f\"ğŸ”„ Resuming from checkpoint: {LAST_CHECKPOINT_PATH}\")\n    checkpoint = torch.load(LAST_CHECKPOINT_PATH)\n    model.load_state_dict(checkpoint['state_dict'])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    start_epoch = checkpoint['epoch'] + 1\n    best_val_f1 = checkpoint['best_val_f1']\n    print(f\"Resuming at Epoch {start_epoch} with Best F1: {best_val_f1:.4f}\")\n\n# --- TRAINING LOOP ---\nscaler = GradScaler()  # For Mixed Precision (Speed)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*70)\nprint(f\"Epochs: {start_epoch} â†’ {epochs}\")\nprint(f\"Batch size: {batch_size}\")\nprint(f\"Learning rate: {learning_rate}\")\nprint(\"=\"*70 + \"\\n\")\n\nfor epoch in range(start_epoch, epochs):\n    model.train()\n    train_loss = 0\n    \n    # 1. TRAINING PHASE\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n    for X, Y in loop:\n        X, Y = X.to(device), Y.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Mixed Precision Context\n        with autocast():\n            outputs = model(X)\n            loss = criterion(outputs, Y)\n            \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        train_loss += loss.item()\n        loop.set_postfix(loss=loss.item())\n        \n    avg_train_loss = train_loss / len(train_loader)\n    \n    # 2. VALIDATION PHASE\n    model.eval()\n    val_preds = []\n    val_targets = []\n    \n    with torch.no_grad():\n        for X, Y in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n            X, Y = X.to(device), Y.to(device)\n            outputs = model(X)\n            \n            # Get class predictions (Argmax)\n            preds = torch.argmax(outputs, dim=1)\n            \n            # Flatten and mask \"No Data\" (0) pixels for metric calc\n            mask = Y != 0\n            val_preds.append(preds[mask].cpu())\n            val_targets.append(Y[mask].cpu())\n            \n    # Concatenate all batches\n    val_preds = torch.cat(val_preds).numpy()\n    val_targets = torch.cat(val_targets).numpy()\n    \n    # Calculate Macro F1\n    val_f1 = f1_score(val_targets, val_preds, average='macro')\n    \n    print(f\"\\nEpoch {epoch+1} Results:\")\n    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n    print(f\"  Val Macro-F1: {val_f1:.4f}\")\n    \n    # Update Scheduler\n    scheduler.step(val_f1)\n    \n    # 3. SAVE CHECKPOINT\n    is_best = val_f1 > best_val_f1\n    if is_best:\n        best_val_f1 = val_f1\n        print(f\"  ğŸ”¥ New Best Model! Macro-F1={best_val_f1:.4f}\")\n        \n    save_checkpoint({\n        'epoch': epoch,\n        'state_dict': model.state_dict(),\n        'best_val_f1': best_val_f1,\n        'optimizer': optimizer.state_dict(),\n    }, is_best, LAST_CHECKPOINT_PATH)\n    \nprint(\"\\n\" + \"=\"*70)\nprint(\"TRAINING COMPLETE\")\nprint(\"=\"*70)\nprint(f\"Best Validation Macro-F1: {best_val_f1:.4f}\")\nprint(f\"Best model saved to: {BEST_MODEL_PATH}\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:19:32.810560Z","iopub.execute_input":"2025-12-04T12:19:32.810851Z","iopub.status.idle":"2025-12-04T13:26:44.984715Z","shell.execute_reply.started":"2025-12-04T12:19:32.810801Z","shell.execute_reply":"2025-12-04T13:26:44.983711Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/3817547071.py:30: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # For Mixed Precision (Speed)\n","output_type":"stream"},{"name":"stdout","text":"\n======================================================================\nSTARTING TRAINING\n======================================================================\nEpochs: 0 â†’ 10\nBatch size: 4\nLearning rate: 0.0001\n======================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 1/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:21<00:00,  2.05it/s, loss=1.14] \nEpoch 1/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:40<00:00,  2.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Results:\n  Train Loss: 1.1162\n  Val Macro-F1: 0.5030\n  ğŸ”¥ New Best Model! Macro-F1=0.5030\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 2/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:00<00:00,  2.17it/s, loss=1.18] \nEpoch 2/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Results:\n  Train Loss: 0.8555\n  Val Macro-F1: 0.6537\n  ğŸ”¥ New Best Model! Macro-F1=0.6537\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 3/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [05:59<00:00,  2.18it/s, loss=0.594]\nEpoch 3/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Results:\n  Train Loss: 0.7808\n  Val Macro-F1: 0.6725\n  ğŸ”¥ New Best Model! Macro-F1=0.6725\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 4/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:00<00:00,  2.17it/s, loss=0.65] \nEpoch 4/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4 Results:\n  Train Loss: 0.7497\n  Val Macro-F1: 0.6812\n  ğŸ”¥ New Best Model! Macro-F1=0.6812\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 5/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:01<00:00,  2.16it/s, loss=0.451]\nEpoch 5/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5 Results:\n  Train Loss: 0.7132\n  Val Macro-F1: 0.7028\n  ğŸ”¥ New Best Model! Macro-F1=0.7028\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 6/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:04<00:00,  2.15it/s, loss=0.561]\nEpoch 6/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6 Results:\n  Train Loss: 0.6938\n  Val Macro-F1: 0.7210\n  ğŸ”¥ New Best Model! Macro-F1=0.7210\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 7/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:01<00:00,  2.17it/s, loss=0.518]\nEpoch 7/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7 Results:\n  Train Loss: 0.6831\n  Val Macro-F1: 0.7174\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 8/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [05:59<00:00,  2.18it/s, loss=0.558]\nEpoch 8/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8 Results:\n  Train Loss: 0.6613\n  Val Macro-F1: 0.7116\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 9/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:01<00:00,  2.17it/s, loss=0.67] \nEpoch 9/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9 Results:\n  Train Loss: 0.6492\n  Val Macro-F1: 0.7207\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/10 [Train]:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3817547071.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 10/10 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 783/783 [06:03<00:00,  2.15it/s, loss=0.743]\nEpoch 10/10 [Val]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:37<00:00,  2.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10 Results:\n  Train Loss: 0.6308\n  Val Macro-F1: 0.7300\n  ğŸ”¥ New Best Model! Macro-F1=0.7300\n  ğŸ”¥ New Best Model saved to models/checkpoints/best_cnn_model.pth\n\n======================================================================\nTRAINING COMPLETE\n======================================================================\nBest Validation Macro-F1: 0.7300\nBest model saved to: models/checkpoints/best_cnn_model.pth\n======================================================================\n","output_type":"stream"}],"execution_count":17},{"id":"81e72669","cell_type":"code","source":"import json\nfrom pathlib import Path\n\n# Create experiment tracking directory\nPath(\"experiments\").mkdir(exist_ok=True)\n\n# Define architectures to test\narchitectures = {\n    'light': AvalancheNet_Light,\n    'medium': AvalancheNet_Medium,\n    'deep': AvalancheNet_Deep,\n    'maxpool': AvalancheNet_MaxPool,\n    'deep_cnn': DeepAvalancheNet,      # NEW: Deep 4-layer CNN\n    'convlstm': AvalancheConvLSTM      # NEW: ConvLSTM\n}\n\n# Configuration for architecture search (shorter epochs)\nsearch_config = {\n    'batch_size': 4,  # Kaggle T4: 16GB VRAM (4x faster than batch_size=1)\n    'learning_rate': 1e-4,\n    'epochs': 3,  # Reduced for faster comparison (was 5)\n    'device': device\n}\n\nresults = {}\n\nprint(\"=\"*70)\nprint(\"ARCHITECTURE SEARCH - WEEK 1\")\nprint(\"=\"*70)\n\nfor arch_name, arch_class in architectures.items():\n    print(f\"\\n{'='*70}\")\n    print(f\"Training: {arch_name.upper()}\")\n    print(f\"{'='*70}\\n\")\n    \n    # Initialize model\n    model = arch_class(\n        in_channels=len(dynamic_features)+4, \n        num_classes=5\n    ).to(device)\n    \n    # Count parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\\n\")\n    \n    # Setup optimizer and loss\n    optimizer = optim.Adam(model.parameters(), lr=search_config['learning_rate'])\n    scaler = GradScaler()  # AMP for faster training\n    \n    # Training loop\n    train_losses = []\n    val_losses = []\n    val_macro_f1s = []\n    \n    for epoch in range(search_config['epochs']):\n        # Training with Mixed Precision\n        model.train()\n        epoch_loss = 0\n        \n        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{search_config['epochs']}\"):\n            x, y = x.to(device), y.to(device)\n            \n            optimizer.zero_grad()\n            \n            # Mixed precision forward pass\n            with autocast():\n                outputs = model(x)\n                loss = criterion(outputs, y)\n            \n            # Scaled backward pass\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            epoch_loss += loss.item()\n        \n        avg_train_loss = epoch_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        # Validation with Macro-F1\n        val_metrics = calculate_metrics(model, val_loader, device, criterion)\n        val_losses.append(val_metrics['loss'])\n        val_macro_f1s.append(val_metrics['macro_f1'])\n        \n        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} | Val Loss={val_metrics['loss']:.4f} | Macro-F1={val_metrics['macro_f1']:.4f}\")\n    \n    # Save results\n    results[arch_name] = {\n        'total_params': total_params,\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_macro_f1s': val_macro_f1s,\n        'final_train_loss': train_losses[-1],\n        'final_val_loss': val_losses[-1],\n        'final_macro_f1': val_macro_f1s[-1]\n    }\n    \n    # Save model checkpoint\n    torch.save(\n        model.state_dict(), \n        f\"experiments/week1_{arch_name}_final.pth\"\n    )\n    \n    # Save config\n    with open(f\"experiments/week1_{arch_name}_config.json\", 'w') as f:\n        json.dump({\n            'architecture': arch_name,\n            'config': search_config,\n            'results': results[arch_name]\n        }, f, indent=2)\n\n# Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"WEEK 1 RESULTS: ARCHITECTURE COMPARISON\")\nprint(\"=\"*70)\n\nfor arch_name, metrics in results.items():\n    print(f\"\\n{arch_name.upper()}:\")\n    print(f\"  Parameters: {metrics['total_params']:,}\")\n    print(f\"  Final Train Loss: {metrics['final_train_loss']:.4f}\")\n    print(f\"  Final Val Loss: {metrics['final_val_loss']:.4f}\")\n    print(f\"  Final Macro-F1: {metrics['final_macro_f1']:.4f}\")\n\n# Find best architecture based on Macro-F1 (not loss!)\nbest_arch = max(results.items(), key=lambda x: x[1]['final_macro_f1'])\nprint(f\"\\n{'='*70}\")\nprint(f\"ğŸ† BEST ARCHITECTURE: {best_arch[0].upper()}\")\nprint(f\"   Validation Loss: {best_arch[1]['final_val_loss']:.4f}\")\nprint(f\"   Macro-F1: {best_arch[1]['final_macro_f1']:.4f}\")\nprint(f\"   Parameters: {best_arch[1]['total_params']:,}\")\nprint(f\"{'='*70}\")\n\n# Save summary\nwith open('experiments/week1_summary.json', 'w') as f:\n    json.dump({\n        'all_results': results,\n        'best_architecture': best_arch[0],\n        'best_val_loss': best_arch[1]['final_val_loss']\n    }, f, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:44.986287Z","iopub.execute_input":"2025-12-04T13:26:44.986588Z","iopub.status.idle":"2025-12-04T13:26:48.500202Z","shell.execute_reply.started":"2025-12-04T13:26:44.986552Z","shell.execute_reply":"2025-12-04T13:26:48.498388Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/3132349021.py:50: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()  # AMP for faster training\n","output_type":"stream"},{"name":"stdout","text":"======================================================================\nARCHITECTURE SEARCH - WEEK 1\n======================================================================\n\n======================================================================\nTraining: LIGHT\n======================================================================\n\nTotal parameters: 68,869\nTrainable parameters: 68,869\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/3:   0%|          | 0/783 [00:00<?, ?it/s]/tmp/ipykernel_47/3132349021.py:68: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\nEpoch 1/3:   1%|          | 6/783 [00:03<07:18,  1.77it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/3132349021.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{search_config['epochs']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":18},{"id":"7beb6033","cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot training curves for all architectures\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))\n\n# Training Loss Comparison\nfor arch_name, metrics in results.items():\n    epochs_range = range(1, len(metrics['train_losses']) + 1)\n    ax1.plot(epochs_range, metrics['train_losses'], label=arch_name, marker='o')\n\nax1.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Validation Loss Comparison\nfor arch_name, metrics in results.items():\n    epochs_range = range(1, len(metrics['val_losses']) + 1)\n    ax2.plot(epochs_range, metrics['val_losses'], label=arch_name, marker='o')\n\nax2.set_title('Validation Loss Comparison', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Loss')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# Macro-F1 Comparison\nfor arch_name, metrics in results.items():\n    epochs_range = range(1, len(metrics['val_macro_f1s']) + 1)\n    ax3.plot(epochs_range, metrics['val_macro_f1s'], label=arch_name, marker='s', linewidth=2)\n\nax3.set_title('Validation Macro-F1 Comparison', fontsize=14, fontweight='bold')\nax3.set_xlabel('Epoch')\nax3.set_ylabel('Macro-F1')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\n# Parameter vs Performance scatter plot\narch_names = list(results.keys())\nparams = [results[a]['total_params'] / 1e6 for a in arch_names]  # In millions\nmacro_f1s = [results[a]['final_macro_f1'] for a in arch_names]\n\nscatter = ax4.scatter(params, macro_f1s, s=300, alpha=0.6, c=range(len(arch_names)), cmap='viridis')\nfor i, name in enumerate(arch_names):\n    ax4.annotate(name.upper(), (params[i], macro_f1s[i]), \n                xytext=(10, 5), textcoords='offset points', fontsize=11, fontweight='bold')\n\nax4.set_xlabel('Model Size (Million Parameters)', fontsize=12)\nax4.set_ylabel('Final Macro-F1', fontsize=12)\nax4.set_title('Model Complexity vs Macro-F1', fontsize=14, fontweight='bold')\nax4.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('experiments/week1_training_curves.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nğŸ“Š Visualizations saved to experiments/ folder\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:48.501423Z","iopub.status.idle":"2025-12-04T13:26:48.501923Z","shell.execute_reply.started":"2025-12-04T13:26:48.501679Z","shell.execute_reply":"2025-12-04T13:26:48.501700Z"}},"outputs":[],"execution_count":null},{"id":"d5c779d9","cell_type":"markdown","source":"## WEEK 2: Hyperparameter Tuning\n\n**Instructions**: \n1. Load the best architecture from Week 1 results\n2. Test different learning rates and dropout values\n3. Run this after reviewing Week 1 results","metadata":{}},{"id":"f1b35b78","cell_type":"code","source":"# Load Week 1 results to determine best architecture\nwith open('experiments/week1_summary.json', 'r') as f:\n    week1_summary = json.load(f)\n\nbest_arch_name = week1_summary['best_architecture']\nprint(f\"ğŸ“Œ Using best architecture from Week 1: {best_arch_name.upper()}\\n\")\n\n# Map architecture name to class\narch_map = {\n    'light': AvalancheNet_Light,\n    'medium': AvalancheNet_Medium,\n    'deep': AvalancheNet_Deep,\n    'maxpool': AvalancheNet_MaxPool,\n    'deep_cnn': DeepAvalancheNet,      # NEW: Deep 4-layer CNN\n    'convlstm': AvalancheConvLSTM      # NEW: ConvLSTM\n}\nBestArchitecture = arch_map[best_arch_name]\n\n# Hyperparameter grid\nlearning_rates = [1e-3, 1e-4, 1e-5]\ndropout_rates = [0.2, 0.3, 0.5] if best_arch_name == 'medium' else [None]\n\n# Configuration for hyperparameter tuning\ntuning_config = {\n    'batch_size': 4,  # 4x faster than batch_size=1\n    'epochs': 6,  # Reduced from 10 (still enough to see trends)\n    'device': device\n}\n\nweek2_results = {}\n\nprint(\"=\"*70)\nprint(\"HYPERPARAMETER TUNING - WEEK 2\")\nprint(\"=\"*70)\n\n# Test learning rates\nfor lr in learning_rates:\n    run_name = f\"lr_{lr:.0e}\"\n    print(f\"\\n{'='*70}\")\n    print(f\"Testing Learning Rate: {lr}\")\n    print(f\"{'='*70}\\n\")\n    \n    model = BestArchitecture(\n        in_channels=len(dynamic_features)+4,\n        num_classes=5\n    ).to(device)\n    \n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scaler = GradScaler()\n    \n    train_losses = []\n    val_losses = []\n    val_macro_f1s = []\n    \n    for epoch in range(tuning_config['epochs']):\n        # Training with AMP\n        model.train()\n        epoch_loss = 0\n        \n        for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            x, y = x.to(device), y.to(device)\n            \n            optimizer.zero_grad()\n            \n            with autocast():\n                outputs = model(x)\n                loss = criterion(outputs, y)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            epoch_loss += loss.item()\n        \n        avg_train_loss = epoch_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        # Validation with Macro-F1\n        val_metrics = calculate_metrics(model, val_loader, device, criterion)\n        val_losses.append(val_metrics['loss'])\n        val_macro_f1s.append(val_metrics['macro_f1'])\n        \n        print(f\"Epoch {epoch+1}: Train={avg_train_loss:.4f} | Val={val_metrics['loss']:.4f} | Macro-F1={val_metrics['macro_f1']:.4f}\")\n    \n    week2_results[run_name] = {\n        'lr': lr,\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'val_macro_f1s': val_macro_f1s,\n        'final_val_loss': val_losses[-1],\n        'final_macro_f1': val_macro_f1s[-1]\n    }\n    \n    torch.save(model.state_dict(), f\"experiments/week2_{run_name}.pth\")\n    \n    with open(f\"experiments/week2_{run_name}_config.json\", 'w') as f:\n        json.dump({\n            'architecture': best_arch_name,\n            'learning_rate': lr,\n            'config': tuning_config,\n            'results': week2_results[run_name]\n        }, f, indent=2)\n\n# Summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"WEEK 2 RESULTS: LEARNING RATE COMPARISON\")\nprint(\"=\"*70)\n\nfor run_name, metrics in week2_results.items():\n    print(f\"\\n{run_name}:\")\n    print(f\"  Learning Rate: {metrics['lr']}\")\n    print(f\"  Final Val Loss: {metrics['final_val_loss']:.4f}\")\n    print(f\"  Final Macro-F1: {metrics['final_macro_f1']:.4f}\")\n\nbest_lr_run = max(week2_results.items(), key=lambda x: x[1]['final_macro_f1'])\nprint(f\"\\n{'='*70}\")\nprint(f\"ğŸ† BEST LEARNING RATE: {best_lr_run[1]['lr']}\")\nprint(f\"   Validation Loss: {best_lr_run[1]['final_val_loss']:.4f}\")\nprint(f\"   Macro-F1: {best_lr_run[1]['final_macro_f1']:.4f}\")\nprint(f\"{'='*70}\")\n\n# Save Week 2 summary\nwith open('experiments/week2_summary.json', 'w') as f:\n    json.dump({\n        'architecture': best_arch_name,\n        'all_results': week2_results,\n        'best_lr': best_lr_run[1]['lr'],\n        'best_val_loss': best_lr_run[1]['final_val_loss']\n    }, f, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:48.502839Z","iopub.status.idle":"2025-12-04T13:26:48.503218Z","shell.execute_reply.started":"2025-12-04T13:26:48.503020Z","shell.execute_reply":"2025-12-04T13:26:48.503038Z"}},"outputs":[],"execution_count":null},{"id":"5cd36075","cell_type":"code","source":"# Visualize Week 2 results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Validation Loss Comparison\nfor run_name, metrics in week2_results.items():\n    epochs_range = range(1, len(metrics['val_losses']) + 1)\n    ax1.plot(epochs_range, metrics['val_losses'], \n            label=f\"LR={metrics['lr']:.0e}\", marker='o', linewidth=2)\n\nax1.set_title('Learning Rate Comparison - Validation Loss', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('Validation Loss', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# Macro-F1 Comparison\nfor run_name, metrics in week2_results.items():\n    epochs_range = range(1, len(metrics['val_macro_f1s']) + 1)\n    ax2.plot(epochs_range, metrics['val_macro_f1s'], \n            label=f\"LR={metrics['lr']:.0e}\", marker='s', linewidth=2)\n\nax2.set_title('Learning Rate Comparison - Macro-F1', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('Macro-F1', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('experiments/week2_lr_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nğŸ“Š Week 2 visualization saved to experiments/ folder\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:48.504875Z","iopub.status.idle":"2025-12-04T13:26:48.505245Z","shell.execute_reply.started":"2025-12-04T13:26:48.505055Z","shell.execute_reply":"2025-12-04T13:26:48.505072Z"}},"outputs":[],"execution_count":null},{"id":"7719ea5b","cell_type":"markdown","source":"## WEEK 3: Final Training\n\n**Instructions**: \n1. Load best architecture and hyperparameters from Week 1-2\n2. Train for 20-30 epochs with early stopping\n3. Save final model for evaluation","metadata":{}},{"id":"2635f6f7","cell_type":"code","source":"# Load best configuration from Week 1 and Week 2\nwith open('experiments/week1_summary.json', 'r') as f:\n    week1_summary = json.load(f)\n\nwith open('experiments/week2_summary.json', 'r') as f:\n    week2_summary = json.load(f)\n\nbest_arch_name = week1_summary['best_architecture']\nbest_lr = week2_summary['best_lr']\n\nprint(\"=\"*70)\nprint(\"FINAL TRAINING - WEEK 3\")\nprint(\"=\"*70)\nprint(f\"Architecture: {best_arch_name.upper()}\")\nprint(f\"Learning Rate: {best_lr}\")\nprint(f\"Epochs: 25 (with early stopping)\")\nprint(\"=\"*70 + \"\\n\")\n\n# Initialize final model\nBestArchitecture = arch_map[best_arch_name]\nfinal_model = BestArchitecture(\n    in_channels=len(dynamic_features)+4,\n    num_classes=5\n).to(device)\n\noptimizer = optim.Adam(final_model.parameters(), lr=best_lr)\nscaler = GradScaler()\n\n# Learning rate scheduler (reduces LR when Macro-F1 plateaus)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='max', factor=0.5, patience=3, verbose=True\n)\n\n# Early stopping based on Macro-F1\nbest_macro_f1 = 0.0\npatience = 5\npatience_counter = 0\n\nfinal_train_losses = []\nfinal_val_losses = []\nfinal_val_macro_f1s = []\nlearning_rates = []\n\nfor epoch in range(25):\n    # Training with Mixed Precision\n    final_model.train()\n    epoch_loss = 0\n    \n    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/25\"):\n        x, y = x.to(device), y.to(device)\n        \n        optimizer.zero_grad()\n        \n        with autocast():\n            outputs = final_model(x)\n            loss = criterion(outputs, y)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        \n        epoch_loss += loss.item()\n    \n    avg_train_loss = epoch_loss / len(train_loader)\n    final_train_losses.append(avg_train_loss)\n    \n    # Validation with Macro-F1\n    val_metrics = calculate_metrics(final_model, val_loader, device, criterion)\n    final_val_losses.append(val_metrics['loss'])\n    final_val_macro_f1s.append(val_metrics['macro_f1'])\n    \n    # Learning rate scheduling based on Macro-F1\n    scheduler.step(val_metrics['macro_f1'])\n    current_lr = optimizer.param_groups[0]['lr']\n    learning_rates.append(current_lr)\n    \n    print(f\"Epoch {epoch+1}: Train={avg_train_loss:.4f} | Val={val_metrics['loss']:.4f} | Macro-F1={val_metrics['macro_f1']:.4f} | LR={current_lr:.2e}\")\n    \n    # Early stopping check based on Macro-F1\n    if val_metrics['macro_f1'] > best_macro_f1:\n        best_macro_f1 = val_metrics['macro_f1']\n        patience_counter = 0\n        # Save best model\n        torch.save(final_model.state_dict(), 'experiments/final_model_best.pth')\n        print(f\"  âœ“ New best model saved (macro_f1={best_macro_f1:.4f})\")\n    else:\n        patience_counter += 1\n        print(f\"  âš  No improvement ({patience_counter}/{patience})\")\n        \n        if patience_counter >= patience:\n            print(f\"\\nâ›” Early stopping triggered at epoch {epoch+1}\")\n            break\n\n# Save final training results\nfinal_results = {\n    'architecture': best_arch_name,\n    'learning_rate': best_lr,\n    'epochs_trained': len(final_train_losses),\n    'train_losses': final_train_losses,\n    'val_losses': final_val_losses,\n    'val_macro_f1s': final_val_macro_f1s,\n    'learning_rates': learning_rates,\n    'best_macro_f1': best_macro_f1\n}\n\nwith open('experiments/week3_final_results.json', 'w') as f:\n    json.dump(final_results, f, indent=2)\n\ntorch.save(final_model.state_dict(), 'experiments/final_model_last_epoch.pth')\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL TRAINING COMPLETE\")\nprint(\"=\"*70)\nprint(f\"Best Macro-F1: {best_macro_f1:.4f}\")\nprint(f\"Total Epochs: {len(final_train_losses)}\")\nprint(f\"Final Learning Rate: {learning_rates[-1]:.2e}\")\nprint(f\"\\nâœ… Models saved:\")\nprint(f\"   - experiments/final_model_best.pth (best macro-f1)\")\nprint(f\"   - experiments/final_model_last_epoch.pth (last epoch)\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:48.506183Z","iopub.status.idle":"2025-12-04T13:26:48.506574Z","shell.execute_reply.started":"2025-12-04T13:26:48.506354Z","shell.execute_reply":"2025-12-04T13:26:48.506371Z"}},"outputs":[],"execution_count":null},{"id":"d5583e4c","cell_type":"code","source":"# Visualize final training results\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n\nepochs_range = range(1, len(final_train_losses) + 1)\n\n# Training vs Validation Loss\nax1.plot(epochs_range, final_train_losses, label='Train Loss', marker='o', linewidth=2)\nax1.plot(epochs_range, final_val_losses, label='Val Loss', marker='s', linewidth=2)\nax1.set_title('Final Training: Loss Curves', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Macro-F1 Curve\nax2.plot(epochs_range, final_val_macro_f1s, label='Val Macro-F1', marker='o', linewidth=2, color='green')\nax2.axhline(y=best_macro_f1, color='r', linestyle='--', label=f'Best={best_macro_f1:.4f}')\nax2.set_title('Final Training: Macro-F1', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Macro-F1')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# Learning Rate Schedule\nax2.plot(epochs_range, learning_rates, color='orange', marker='D', linewidth=2)\nax2.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Learning Rate')\nax2.set_yscale('log')\nax2.grid(True, alpha=0.3)\n\n# Overfitting Gap (Train - Val Loss)\ngap = [t - v for t, v in zip(final_train_losses, final_val_losses)]\nax3.plot(epochs_range, gap, color='purple', marker='^', linewidth=2)\nax3.axhline(y=0, color='black', linestyle='--', linewidth=1)\nax3.set_title('Overfitting Gap (Train Loss - Val Loss)', fontsize=14, fontweight='bold')\nax3.set_xlabel('Epoch')\nax3.set_ylabel('Gap')\nax3.grid(True, alpha=0.3)\n\n# Summary comparison: Week 1 â†’ Week 2 â†’ Week 3\nstages = ['Week 1\\n(Arch Search)', 'Week 2\\n(LR Tuning)', 'Week 3\\n(Final)']\nval_losses_summary = [\n    week1_summary['best_val_loss'],\n    week2_summary['best_val_loss'],\n    final_results['best_macro_f1']  # Use best_macro_f1 instead\n]\n\nbars = ax4.bar(stages, val_losses_summary, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.7)\nax4.set_title('Progressive Improvement Across 3 Weeks', fontsize=14, fontweight='bold')\nax4.set_ylabel('Best Validation Loss')\nax4.grid(True, axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor bar, val in zip(bars, val_losses_summary):\n    height = bar.get_height()\n    ax4.text(bar.get_x() + bar.get_width()/2., height,\n             f'{val:.4f}', ha='center', va='bottom', fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('experiments/week3_final_training.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nğŸ“Š Final training visualizations saved to experiments/week3_final_training.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:48.507639Z","iopub.status.idle":"2025-12-04T13:26:48.508010Z","shell.execute_reply.started":"2025-12-04T13:26:48.507817Z","shell.execute_reply":"2025-12-04T13:26:48.507835Z"}},"outputs":[],"execution_count":null},{"id":"a7755d37","cell_type":"markdown","source":"## Summary: 3-Week Training Results\n\n**This notebook implements a systematic 3-week training approach:**\n\n### Week 1: Architecture Search (3-4 hours)\n- Tested 4 architecture variants (Light, Medium, Deep, MaxPool)\n- 3 epochs per architecture (fast screening)\n- Identified best architecture based on validation loss\n\n### Week 2: Hyperparameter Tuning (9-12 hours)\n- Tested 3 learning rates on best architecture\n- 6 epochs per configuration\n- Found optimal learning rate\n\n### Week 3: Final Training (10-12 hours)\n- Trained best model with optimal hyperparameters\n- Up to 25 epochs with early stopping\n- Learning rate scheduling and model checkpointing\n\n### Key Features:\n- **Fast**: Optimized for Kaggle T4 GPU (batch_size=4, 16GB VRAM)\n- **Reproducible**: All configurations saved to JSON\n- **Memory-efficient**: Sequential training, no grid search\n- **Well-documented**: Visualizations at each stage\n\n### Total GPU Time: ~25-32 hours âœ… (fits within Kaggle's 30 hrs/week limit!)\n\n### âš ï¸ Important: Train/Validation/Test Split\n\n**Proper Data Splitting:**\n- **Training set (80%)**: Used for model training (Weeks 1-3)\n- **Validation set (20% of train)**: Used for hyperparameter tuning\n- **Test set (completely held out)**: Only used ONCE for final evaluation after Week 3\n\n**Critical Rules:**\n1. âœ… Normalization stats calculated **only from training data**\n2. âœ… Validation set split from training data (80/20)\n3. âœ… Test set never touched during Weeks 1-3\n4. âœ… Final model evaluated on test set once after all tuning complete\n\nThis prevents **data leakage** and ensures fair evaluation!\n\n**Next Steps**: Model evaluation and comparison with Random Forest baseline","metadata":{}},{"id":"31e1767f","cell_type":"markdown","source":"## Final Evaluation on Test Set\n\n**Run this ONLY AFTER completing all 3 weeks of training!**\n\nThis evaluates the final model on the completely held-out test set.","metadata":{}},{"id":"5165c3e1","cell_type":"code","source":"# Load best model from Week 3\nfinal_model = arch_map[best_arch_name](\n    in_channels=len(dynamic_features)+4,\n    num_classes=5\n).to(device)\n\nfinal_model.load_state_dict(torch.load('experiments/final_model_best.pth'))\nfinal_model.eval()\n\nprint(\"=\"*70)\nprint(\"FINAL TEST SET EVALUATION\")\nprint(\"=\"*70)\nprint(f\"Test samples: {len(test_dates)}\")\nprint(\"=\"*70 + \"\\n\")\n\n# Create test dataset and loader\ntest_ds = AvalancheDataset(test_dates, dynamic_dir, target_dir, static_file, stats, dynamic_features)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n\n# Evaluate on test set\ntest_loss = 0\nall_predictions = []\nall_targets = []\n\nwith torch.no_grad():\n    for x, y in tqdm(test_loader, desc=\"Testing\"):\n        x, y = x.to(device), y.to(device)\n        \n        outputs = final_model(x)\n        loss = criterion(outputs, y)\n        test_loss += loss.item()\n        \n        # Get predictions (class with highest probability)\n        preds = torch.argmax(outputs, dim=1)\n        \n        all_predictions.append(preds.cpu().numpy())\n        all_targets.append(y.cpu().numpy())\n\navg_test_loss = test_loss / len(test_loader)\n\nprint(f\"\\n{'='*70}\")\nprint(f\"TEST SET RESULTS\")\nprint(f\"{'='*70}\")\nprint(f\"Test Loss: {avg_test_loss:.4f}\")\nprint(f\"\\nâš ï¸  This is the ONLY time the test set has been evaluated!\")\nprint(f\"{'='*70}\")\n\n# Save test results\ntest_results = {\n    'test_loss': avg_test_loss,\n    'architecture': best_arch_name,\n    'learning_rate': best_lr,\n    'num_test_samples': len(test_dates)\n}\n\nwith open('experiments/final_test_results.json', 'w') as f:\n    json.dump(test_results, f, indent=2)\n\nprint(\"\\nâœ… Test results saved to experiments/final_test_results.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T13:26:48.508720Z","iopub.status.idle":"2025-12-04T13:26:48.509117Z","shell.execute_reply.started":"2025-12-04T13:26:48.508908Z","shell.execute_reply":"2025-12-04T13:26:48.508927Z"}},"outputs":[],"execution_count":null}]}